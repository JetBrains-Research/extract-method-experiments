COMMIT ID: 4a1eea700766da2f175ac7eaba6064f0d7f0ff03
URL: https://github.com/apache/storm/commit/4a1eea700766da2f175ac7eaba6064f0d7f0ff03
DESCRIPTION: Extract Method	public authenticated(c Channel) : void extracted from public channelActive(c Channel) : void in class org.apache.storm.messaging.netty.Server
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/4a1eea700766da2f175ac7eaba6064f0d7f0ff03/storm-client/src/jvm/org/apache/storm/messaging/netty/Server.java
REFACTORING URL: https://github.com/apache/storm/blob/4a1eea700766da2f175ac7eaba6064f0d7f0ff03/storm-client/src/jvm/org/apache/storm/messaging/netty/Server.java#L290
DIRECTLY EXTRACTED OPERATION:
    public void authenticated(Channel c) {
        if (isNettyAuthRequired) {
            LOG.debug("The channel {} is active and authenticated", c);
        } else {
            LOG.debug("The channel {} is active", c);
        }
        if (newConnectionResponse != null) {
            c.writeAndFlush(newConnectionResponse.get(), c.voidPromise());
        }
    }

PARAMS COUNT: 1
IS VOID METHOD: true
FRAGMENT LENGTH: 368
FRAGMENT LINE AVG SIZE: 33.45454545454545
DEPTHS:
1 2 3 3 3 2 2 3 2 1 1 
AREA: 23
AVG DEPTH: 2.090909090909091
NUMBER OF LINES IN FRAGMENT: 11
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: f1716be3d630c44c93787500af9cee427652f548
URL: https://github.com/apache/storm/commit/f1716be3d630c44c93787500af9cee427652f548
DESCRIPTION: Extract Method	public genSupervisorsWithRacksAndNuma(numRacks int, numSupersPerRack int, numaZonesPerHost int, numPorts int, rackStart int, superInRackStart int, cpu double, mem double, miscResources Map<String,Double>, numaResourceMultiplier double) : Map<String,SupervisorDetails> extracted from public genSupervisorsWithRacks(numRacks int, numSupersPerRack int, numPorts int, rackStart int, superInRackStart int, cpu double, mem double, miscResources Map<String,Double>) : Map<String,SupervisorDetails> in class org.apache.storm.scheduler.resource.TestUtilsForResourceAwareScheduler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/f1716be3d630c44c93787500af9cee427652f548/storm-server/src/test/java/org/apache/storm/scheduler/resource/TestUtilsForResourceAwareScheduler.java
REFACTORING URL: https://github.com/apache/storm/blob/f1716be3d630c44c93787500af9cee427652f548/storm-server/src/test/java/org/apache/storm/scheduler/resource/TestUtilsForResourceAwareScheduler.java#L200
DIRECTLY EXTRACTED OPERATION:
     * Takes one additional parameter numaZonesPerHost. This parameter determines how many supervisors
     * will be created on the same host. If numaResourceMultiplier is set to a factor below 1.0, then
     * each subsequent numa zone will have corresponding lower cpu/mem than previous numa zone.
     *
     * @param numRacks
     * @param numSupersPerRack
     * @param numaZonesPerHost
     * @param numPorts
     * @param rackStart
     * @param superInRackStart
     * @param cpu
     * @param mem
     * @param miscResources
     * @param numaResourceMultiplier - cpu/mem resource for each numaZone is multiplied by this factor to obtain uneven resources
     * @return
     */
    public static Map<String, SupervisorDetails> genSupervisorsWithRacksAndNuma(
            int numRacks, int numSupersPerRack, int numaZonesPerHost, int numPorts, int rackStart, int superInRackStart,
            double cpu, double mem, Map<String, Double> miscResources, double numaResourceMultiplier) {
        Map<String, SupervisorDetails> retList = new HashMap<>();
        for (int rack = rackStart; rack < numRacks + rackStart; rack++) {
            for (int superInRack = superInRackStart; superInRack < (numSupersPerRack + superInRackStart); superInRack++) {
                List<Number> ports = new LinkedList<>();
                for (int p = 0; p < numPorts; p++) {
                    ports.add(p);
                }
                String superId;
                String host;
                int numaZone = superInRack % numaZonesPerHost;
                if (numaZonesPerHost > 1) {
                    // multiple supervisors per host
                    int hostInRack = superInRack / numaZonesPerHost;
                    superId = String.format("r%03ds%03dn%d", rack, superInRack, numaZone);
                    host = String.format("host-%03d-rack-%03d", hostInRack, rack);
                } else {
                    superId = String.format("r%03ds%03d", rack, superInRack);
                    host = String.format("host-%03d-rack-%03d", superInRack, rack);
                }
                Map<String, Double> resourceMap = new HashMap<>();
                resourceMap.put(Config.SUPERVISOR_CPU_CAPACITY, cpu * Math.pow(numaResourceMultiplier, numaZone));
                resourceMap.put(Config.SUPERVISOR_MEMORY_CAPACITY_MB, mem * Math.pow(numaResourceMultiplier, numaZone));
                resourceMap.putAll(miscResources);
                SupervisorDetails sup = new SupervisorDetails(superId, host, null, ports,
                    NormalizedResources.RESOURCE_NAME_NORMALIZER.normalizedResourceMap(resourceMap));
                retList.put(sup.getId(), sup);

            }
        }
        return retList;
    }

PARAMS COUNT: 10
IS VOID METHOD: false
FRAGMENT LENGTH: 2737
FRAGMENT LINE AVG SIZE: 53.666666666666664
DEPTHS:
0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 4 4 5 4 4 4 4 4 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 3 2 2 1 1 
AREA: 138
AVG DEPTH: 2.7058823529411766
NUMBER OF LINES IN FRAGMENT: 51
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 3cc4797e56cf30dc04c8c8dcf133534522cc87eb
URL: https://github.com/apache/storm/commit/3cc4797e56cf30dc04c8c8dcf133534522cc87eb
DESCRIPTION: Extract Method	public prepare(topoConf Map<String,Object>, metricRegistry StormMetricRegistry) : void extracted from public prepare(topoConf Map<String,Object>) : void in class org.apache.storm.messaging.netty.Context
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/3cc4797e56cf30dc04c8c8dcf133534522cc87eb/storm-client/src/jvm/org/apache/storm/messaging/netty/Context.java
REFACTORING URL: https://github.com/apache/storm/blob/3cc4797e56cf30dc04c8c8dcf133534522cc87eb/storm-client/src/jvm/org/apache/storm/messaging/netty/Context.java#L46
DIRECTLY EXTRACTED OPERATION:
    public void prepare(Map<String, Object> topoConf, StormMetricRegistry metricRegistry) {
        this.topoConf = topoConf;
        serverConnections = new ArrayList<>();

        //each context will have a single client channel worker event loop group
        int maxWorkers = ObjectReader.getInt(topoConf.get(Config.STORM_MESSAGING_NETTY_CLIENT_WORKER_THREADS));
        ThreadFactory workerFactory = new NettyRenameThreadFactory("client" + "-worker");
        // 0 means DEFAULT_EVENT_LOOP_THREADS
        // https://github.com/netty/netty/blob/netty-4.1.24.Final/transport/src/main/java/io/netty/channel/MultithreadEventLoopGroup.java#L40
        this.workerEventLoopGroup = new NioEventLoopGroup(maxWorkers > 0 ? maxWorkers : 0, workerFactory);

        clientScheduleService = new HashedWheelTimer(new NettyRenameThreadFactory("client-schedule-service"));
        this.metricRegistry = metricRegistry;
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 917
FRAGMENT LINE AVG SIZE: 61.13333333333333
DEPTHS:
1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 
AREA: 27
AVG DEPTH: 1.8
NUMBER OF LINES IN FRAGMENT: 15
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 254a98db0966914bc07094e168667e1a851affcf
URL: https://github.com/apache/storm/commit/254a98db0966914bc07094e168667e1a851affcf
DESCRIPTION: Extract Method	private computeComponentMap(topology StormTopology) : Map<String,Component> extracted from public getComponents() : Map<String,Component> in class org.apache.storm.scheduler.TopologyDetails
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/254a98db0966914bc07094e168667e1a851affcf/storm-server/src/main/java/org/apache/storm/scheduler/TopologyDetails.java
REFACTORING URL: https://github.com/apache/storm/blob/254a98db0966914bc07094e168667e1a851affcf/storm-server/src/main/java/org/apache/storm/scheduler/TopologyDetails.java#L219
DIRECTLY EXTRACTED OPERATION:
     * Compute a map of user topology specific components.
     *
     * @param topology                 userTopology
     * @return a map of Component Id to Component
     */
    private Map<String, Component> computeComponentMap(StormTopology topology) {
        Map<String, Component> ret = new HashMap<>();

        Map<String, SpoutSpec> spouts = topology.get_spouts();
        Map<String, Bolt> bolts = topology.get_bolts();

        if (spouts != null) {
            for (Map.Entry<String, SpoutSpec> entry : spouts.entrySet()) {
                String compId = entry.getKey();
                SpoutSpec spout = entry.getValue();
                if (!Utils.isSystemId(compId)) {
                    Component comp = new Component(ComponentType.SPOUT, compId, componentToExecs(compId), spout.get_common().get_inputs());
                    ret.put(compId, comp);
                }
            }
        }
        if (bolts != null) {
            for (Map.Entry<String, Bolt> entry : bolts.entrySet()) {
                String compId = entry.getKey();
                Bolt bolt = entry.getValue();
                if (!Utils.isSystemId(compId)) {
                    Component comp = new Component(ComponentType.BOLT, compId, componentToExecs(compId), bolt.get_common().get_inputs());
                    ret.put(compId, comp);
                }
            }
        }

        //Link the components together
        if (spouts != null) {
            for (Map.Entry<String, SpoutSpec> entry : spouts.entrySet()) {
                Component spout = ret.get(entry.getKey());
                for (String parentId : getInputsTo(entry.getValue().get_common())) {
                    ret.get(parentId).addChild(spout);
                }
            }
        }

        if (bolts != null) {
            for (Map.Entry<String, Bolt> entry : bolts.entrySet()) {
                Component bolt = ret.get(entry.getKey());
                for (String parentId : getInputsTo(entry.getValue().get_common())) {
                    ret.get(parentId).addChild(bolt);
                }
            }
        }
        return ret;
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 2126
FRAGMENT LINE AVG SIZE: 40.113207547169814
DEPTHS:
0 1 1 1 1 1 2 2 2 2 2 2 3 4 4 4 5 5 4 3 2 2 3 4 4 4 5 5 4 3 2 2 2 2 3 4 4 5 4 3 2 2 2 3 4 4 5 4 3 2 2 1 1 
AREA: 151
AVG DEPTH: 2.849056603773585
NUMBER OF LINES IN FRAGMENT: 53
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 935f74c6abd705c1ce9833ee88e092df097c17a5
URL: https://github.com/apache/storm/commit/935f74c6abd705c1ce9833ee88e092df097c17a5
DESCRIPTION: Extract Method	public writeScript(dir String, command List<String>, environment Map<String,String>, umask String) : String extracted from public writeScript(dir String, command List<String>, environment Map<String,String>) : String in class org.apache.storm.utils.ServerUtils
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/935f74c6abd705c1ce9833ee88e092df097c17a5/storm-server/src/main/java/org/apache/storm/utils/ServerUtils.java
REFACTORING URL: https://github.com/apache/storm/blob/935f74c6abd705c1ce9833ee88e092df097c17a5/storm-server/src/main/java/org/apache/storm/utils/ServerUtils.java#L292
DIRECTLY EXTRACTED OPERATION:
     * Writes a posix shell script file to be executed in its own process.
     *
     * @param dir         the directory under which the script is to be written
     * @param command     the command the script is to execute
     * @param environment optional environment variables to set before running the script's command. May be  null.
     * @param umask umask to be set. It can be null.
     * @return the path to the script that has been written
     */
    public static String writeScript(String dir, List<String> command,
                                     Map<String, String> environment, String umask) throws IOException {
        String path = scriptFilePath(dir);
        try (BufferedWriter out = new BufferedWriter(new FileWriter(path))) {
            out.write("#!/bin/bash");
            out.newLine();
            if (environment != null) {
                for (String k : environment.keySet()) {
                    String v = environment.get(k);
                    if (v == null) {
                        v = "";
                    }
                    out.write(shellCmd(
                        Arrays.asList(
                            "export", k + "=" + v)));
                    out.write(";");
                    out.newLine();
                }
            }
            out.newLine();
            if (umask != null) {
                out.write("umask " + umask);
                out.newLine();
            }
            out.write("exec " + shellCmd(command) + ";");
        }
        return path;
    }

PARAMS COUNT: 4
IS VOID METHOD: false
FRAGMENT LENGTH: 1542
FRAGMENT LINE AVG SIZE: 41.67567567567568
DEPTHS:
0 1 1 1 1 1 1 1 1 1 2 2 3 3 3 4 5 5 6 5 5 5 5 5 5 4 3 3 3 4 4 3 3 2 2 1 1 
AREA: 105
AVG DEPTH: 2.8378378378378377
NUMBER OF LINES IN FRAGMENT: 37
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: f1c161949db066c35839116070892b86b8bd7e67
URL: https://github.com/apache/storm/commit/f1c161949db066c35839116070892b86b8bd7e67
DESCRIPTION: Extract Method	private getTopologySummaryImpl(topoId String, base StormBase) : TopologySummary extracted from private getClusterInfoImpl() : ClusterSummary in class org.apache.storm.daemon.nimbus.Nimbus
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/f1c161949db066c35839116070892b86b8bd7e67/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java
REFACTORING URL: https://github.com/apache/storm/blob/f1c161949db066c35839116070892b86b8bd7e67/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L3032
DIRECTLY EXTRACTED OPERATION:
        IStormClusterState state = stormClusterState;
        Assignment assignment = state.assignmentInfo(topoId, null);

        int numTasks = 0;
        int numExecutors = 0;
        int numWorkers = 0;
        if (assignment != null && assignment.is_set_executor_node_port()) {
            for (List<Long> ids : assignment.get_executor_node_port().keySet()) {
                numTasks += StormCommon.executorIdToTasks(ids).size();
            }

            numExecutors = assignment.get_executor_node_port_size();
            numWorkers = new HashSet<>(assignment.get_executor_node_port().values()).size();
        }

        TopologySummary summary = new TopologySummary(topoId, base.get_name(), numTasks, numExecutors, numWorkers,
                                                      Time.deltaSecs(base.get_launch_time_secs()), extractStatusStr(base));
        try {
            StormTopology topo = tryReadTopology(topoId, topoCache);
            if (topo != null && topo.is_set_storm_version()) {
                summary.set_storm_version(topo.get_storm_version());
            }
        } catch (NotAliveException e) {
            //Ignored it is not set
        }

        if (base.is_set_owner()) {
            summary.set_owner(base.get_owner());
        }

        if (base.is_set_topology_version()) {
            summary.set_topology_version(base.get_topology_version());
        }

        String status = idToSchedStatus.get().get(topoId);
        if (status != null) {
            summary.set_sched_status(status);
        }
        TopologyResources resources = getResourcesForTopology(topoId, base);
        if (resources != null) {
            summary.set_requested_memonheap(resources.getRequestedMemOnHeap());
            summary.set_requested_memoffheap(resources.getRequestedMemOffHeap());
            summary.set_requested_cpu(resources.getRequestedCpu());
            summary.set_requested_generic_resources(resources.getRequestedGenericResources());
            summary.set_assigned_memonheap(resources.getAssignedMemOnHeap());
            summary.set_assigned_memoffheap(resources.getAssignedMemOffHeap());
            summary.set_assigned_cpu(resources.getAssignedCpu());
            summary.set_assigned_generic_resources(resources.getAssignedGenericResources());
        }
        try {
            summary.set_replication_count(getBlobReplicationCount(ConfigUtils.masterStormCodeKey(topoId)));
        } catch (Exception e) {
            // This could fail if a blob gets deleted by mistake.  Don't crash nimbus.
            LOG.error("Unable to find blob entry", e);
        }
        return summary;
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 2646
FRAGMENT LINE AVG SIZE: 45.62068965517241
DEPTHS:
1 2 2 2 2 2 2 3 4 3 3 3 3 2 2 2 2 2 3 3 4 3 3 3 2 2 2 3 2 2 2 3 2 2 2 2 3 2 2 2 3 3 3 3 3 3 3 3 2 2 3 3 3 3 2 2 1 1 
AREA: 142
AVG DEPTH: 2.4482758620689653
NUMBER OF LINES IN FRAGMENT: 58
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private getTopologySummariesImpl() : List<TopologySummary> extracted from private getClusterInfoImpl() : ClusterSummary in class org.apache.storm.daemon.nimbus.Nimbus
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/f1c161949db066c35839116070892b86b8bd7e67/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java
REFACTORING URL: https://github.com/apache/storm/blob/f1c161949db066c35839116070892b86b8bd7e67/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L3016
DIRECTLY EXTRACTED OPERATION:
        IStormClusterState state = stormClusterState;
        List<TopologySummary> topologySummaries = new ArrayList<>();
        Map<String, StormBase> bases = state.topologyBases();
        for (Entry<String, StormBase> entry : bases.entrySet()) {
            StormBase base = entry.getValue();
            if (base == null) {
                continue;
            }
            String topoId = entry.getKey();
            TopologySummary summary = getTopologySummaryImpl(topoId, base);
            topologySummaries.add(summary);
        }
        return topologySummaries;
    }

IS VOID METHOD: false
FRAGMENT LENGTH: 585
FRAGMENT LINE AVG SIZE: 39.0
DEPTHS:
1 2 2 2 3 3 4 3 3 3 3 2 2 1 1 
AREA: 35
AVG DEPTH: 2.3333333333333335
NUMBER OF LINES IN FRAGMENT: 15
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private getTopologyInfoWithOptsImpl(topoId String, options GetInfoOptions) : TopologyInfo extracted from public getTopologyInfoWithOpts(topoId String, options GetInfoOptions) : TopologyInfo in class org.apache.storm.daemon.nimbus.Nimbus
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/f1c161949db066c35839116070892b86b8bd7e67/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java
REFACTORING URL: https://github.com/apache/storm/blob/f1c161949db066c35839116070892b86b8bd7e67/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L4156
DIRECTLY EXTRACTED OPERATION:
        AuthorizationException, InvalidTopologyException, Exception {
        CommonTopoInfo common = getCommonTopoInfo(topoId, "getTopologyInfo");
        if (common.base == null) {
            throw new WrappedNotAliveException(topoId);
        }
        IStormClusterState state = stormClusterState;
        NumErrorsChoice numErrChoice = Utils.OR(options.get_num_err_choice(), NumErrorsChoice.ALL);
        Map<String, List<ErrorInfo>> errors = new HashMap<>();
        for (String component : common.allComponents) {
            switch (numErrChoice) {
                case NONE:
                    errors.put(component, Collections.emptyList());
                    break;
                case ONE:
                    List<ErrorInfo> errList = new ArrayList<>();
                    ErrorInfo info = state.lastError(topoId, component);
                    if (info != null) {
                        errList.add(info);
                    }
                    errors.put(component, errList);
                    break;
                case ALL:
                    errors.put(component, state.errors(topoId, component));
                    break;
                default:
                    LOG.warn("Got invalid NumErrorsChoice '{}'", numErrChoice);
                    errors.put(component, state.errors(topoId, component));
                    break;
            }
        }

        List<ExecutorSummary> summaries = new ArrayList<>();
        if (common.assignment != null) {
            for (Entry<List<Long>, NodeInfo> entry : common.assignment.get_executor_node_port().entrySet()) {
                NodeInfo ni = entry.getValue();
                ExecutorInfo execInfo = toExecInfo(entry.getKey());
                Map<String, String> nodeToHost = common.assignment.get_node_host();
                Map<String, Object> heartbeat = common.beats.get(ClientStatsUtil.convertExecutor(entry.getKey()));
                if (heartbeat == null) {
                    heartbeat = Collections.emptyMap();
                }
                ExecutorSummary summ = new ExecutorSummary(execInfo,
                                                           common.taskToComponent.get(execInfo.get_task_start()),
                                                           nodeToHost.get(ni.get_node()), ni.get_port_iterator().next().intValue(),
                                                           (Integer) heartbeat.getOrDefault("uptime", 0));

                //heartbeats "stats"
                Map ex = (Map) heartbeat.get("stats");
                if (ex != null) {
                    ExecutorStats stats = StatsUtil.thriftifyExecutorStats(ex);
                    summ.set_stats(stats);
                }
                summaries.add(summ);
            }
        }
        TopologyInfo topoInfo = new TopologyInfo(topoId, common.topoName, Time.deltaSecs(common.launchTimeSecs),
                                                 summaries, extractStatusStr(common.base), errors);
        if (common.topology.is_set_storm_version()) {
            topoInfo.set_storm_version(common.topology.get_storm_version());
        }
        if (common.base.is_set_owner()) {
            topoInfo.set_owner(common.base.get_owner());
        }
        String schedStatus = idToSchedStatus.get().get(topoId);
        if (schedStatus != null) {
            topoInfo.set_sched_status(schedStatus);
        }
        TopologyResources resources = getResourcesForTopology(topoId, common.base);
        if (resources != null && underlyingScheduler instanceof ResourceAwareScheduler) {
            topoInfo.set_requested_memonheap(resources.getRequestedMemOnHeap());
            topoInfo.set_requested_memoffheap(resources.getRequestedMemOffHeap());
            topoInfo.set_requested_cpu(resources.getRequestedCpu());
            topoInfo.set_assigned_memonheap(resources.getAssignedMemOnHeap());
            topoInfo.set_assigned_memoffheap(resources.getAssignedMemOffHeap());
            topoInfo.set_assigned_cpu(resources.getAssignedCpu());

        }
        if (common.base.is_set_component_debug()) {
            topoInfo.set_component_debug(common.base.get_component_debug());
        }
        topoInfo.set_replication_count(getBlobReplicationCount(ConfigUtils.masterStormCodeKey(topoId)));
        return topoInfo;
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 4328
FRAGMENT LINE AVG SIZE: 51.523809523809526
DEPTHS:
1 2 2 3 2 2 2 2 2 3 4 4 4 4 4 4 4 5 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 3 4 4 4 4 4 5 4 4 4 4 4 4 4 4 4 5 5 4 4 3 2 2 2 2 3 2 2 3 2 2 2 3 2 2 2 3 3 3 3 3 3 3 2 2 3 2 2 2 1 1 
AREA: 259
AVG DEPTH: 3.0833333333333335
NUMBER OF LINES IN FRAGMENT: 84
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 39a6fba632a70f1d4684489b5b4dc6cb98a34662
URL: https://github.com/apache/storm/commit/39a6fba632a70f1d4684489b5b4dc6cb98a34662
DESCRIPTION: Extract Method	private registerGauge(metricNames MetricNames, gauge Gauge<T>, taskId int, componentId String, streamId String) : Gauge<T> extracted from public gauge(name String, gauge Gauge<T>, context TopologyContext) : Gauge<T> in class org.apache.storm.metrics2.StormMetricRegistry
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/39a6fba632a70f1d4684489b5b4dc6cb98a34662/storm-client/src/jvm/org/apache/storm/metrics2/StormMetricRegistry.java
REFACTORING URL: https://github.com/apache/storm/blob/39a6fba632a70f1d4684489b5b4dc6cb98a34662/storm-client/src/jvm/org/apache/storm/metrics2/StormMetricRegistry.java#L182
DIRECTLY EXTRACTED OPERATION:
                                       String componentId, String streamId) {
        TaskMetricDimensions taskMetricDimensions = new TaskMetricDimensions(taskId, componentId, streamId, this);
        TaskMetricRepo repo = taskMetrics.computeIfAbsent(taskMetricDimensions, (k) -> new TaskMetricRepo());
        repo.addGauge(metricNames.getShortName(), gauge);
        gauge = registry.register(metricNames.getLongName(), gauge);
        return gauge;
    }

PARAMS COUNT: 5
IS VOID METHOD: false
FRAGMENT LENGTH: 459
FRAGMENT LINE AVG SIZE: 57.375
DEPTHS:
1 2 2 2 2 2 1 1 
AREA: 13
AVG DEPTH: 1.625
NUMBER OF LINES IN FRAGMENT: 8
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private init(registry MetricRegistry, metricRegistryProvider MetricRegistryProvider, reporterConf Map<String,Object>) : void extracted from public prepare(registry MetricRegistry, topoConf Map<String,Object>, reporterConf Map<String,Object>) : void in class org.apache.storm.metrics2.reporters.ConsoleStormReporter
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/39a6fba632a70f1d4684489b5b4dc6cb98a34662/storm-client/src/jvm/org/apache/storm/metrics2/reporters/ConsoleStormReporter.java
REFACTORING URL: https://github.com/apache/storm/blob/39a6fba632a70f1d4684489b5b4dc6cb98a34662/storm-client/src/jvm/org/apache/storm/metrics2/reporters/ConsoleStormReporter.java#L45
DIRECTLY EXTRACTED OPERATION:
        LOG.debug("Preparing ConsoleReporter");
        ConsoleReporter.Builder builder = ConsoleReporter.forRegistry(registry);

        builder.outputTo(System.out);
        Locale locale = ClientMetricsUtils.getMetricsReporterLocale(reporterConf);
        if (locale != null) {
            builder.formattedFor(locale);
        }

        TimeUnit rateUnit = ClientMetricsUtils.getMetricsRateUnit(reporterConf);
        if (rateUnit != null) {
            builder.convertRatesTo(rateUnit);
        }

        TimeUnit durationUnit = ClientMetricsUtils.getMetricsDurationUnit(reporterConf);
        if (durationUnit != null) {
            builder.convertDurationsTo(durationUnit);
        }

        StormMetricsFilter filter = getMetricsFilter(reporterConf);
        if (filter != null) {
            builder.filter(filter);
        }

        //defaults to 10
        reportingPeriod = getReportPeriod(reporterConf);

        //defaults to seconds
        reportingPeriodUnit = getReportPeriodUnit(reporterConf);

        ScheduledReporter consoleReporter = builder.build();

        boolean reportDimensions = isReportDimensionsEnabled(reporterConf);
        if (reportDimensions) {
            if (metricRegistryProvider == null) {
                throw new RuntimeException("MetricRegistryProvider is required to enable reporting dimensions");
            }
            if (rateUnit == null) {
                rateUnit = TimeUnit.SECONDS;
            }
            if (durationUnit == null) {
                durationUnit = TimeUnit.MILLISECONDS;
            }
            DimensionalReporter dimensionalReporter = new DimensionalReporter(metricRegistryProvider, consoleReporter, this,
                    "ConsoleDimensionalReporter",
                    filter, rateUnit, durationUnit, null, true);
            reporter = dimensionalReporter;
        } else {
            reporter = consoleReporter;
        }
    }

PARAMS COUNT: 3
IS VOID METHOD: true
FRAGMENT LENGTH: 1926
FRAGMENT LINE AVG SIZE: 37.03846153846154
DEPTHS:
1 2 2 2 2 2 3 2 2 2 2 3 2 2 2 2 3 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 3 4 3 3 4 3 3 4 3 3 3 3 3 3 3 2 1 1 
AREA: 123
AVG DEPTH: 2.3653846153846154
NUMBER OF LINES IN FRAGMENT: 52
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: e83fafcb884f4c630dbbe4a8656a4f93a41abe5b
URL: https://github.com/apache/storm/commit/e83fafcb884f4c630dbbe4a8656a4f93a41abe5b
DESCRIPTION: Extract Method	private addMeteredDatapoints(baseName String, metered Metered, dataPoints List<IMetricsConsumer.DataPoint>) : void extracted from private processMeters(taskId int, dataPoints List<IMetricsConsumer.DataPoint>) : void in class org.apache.storm.executor.Executor
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e83fafcb884f4c630dbbe4a8656a4f93a41abe5b/storm-client/src/jvm/org/apache/storm/executor/Executor.java
REFACTORING URL: https://github.com/apache/storm/blob/e83fafcb884f4c630dbbe4a8656a4f93a41abe5b/storm-client/src/jvm/org/apache/storm/executor/Executor.java#L413
DIRECTLY EXTRACTED OPERATION:
        IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(baseName + ".count", metered.getCount());
        dataPoints.add(dataPoint);
        addConvertedMetric(baseName, ".m1_rate", metered.getOneMinuteRate(), dataPoints);
        addConvertedMetric(baseName, ".m5_rate", metered.getFiveMinuteRate(), dataPoints);
        addConvertedMetric(baseName, ".m15_rate", metered.getFifteenMinuteRate(), dataPoints);
        addConvertedMetric(baseName, ".mean_rate", metered.getMeanRate(), dataPoints);
    }

PARAMS COUNT: 3
IS VOID METHOD: true
FRAGMENT LENGTH: 525
FRAGMENT LINE AVG SIZE: 65.625
DEPTHS:
1 2 2 2 2 2 1 1 
AREA: 13
AVG DEPTH: 1.625
NUMBER OF LINES IN FRAGMENT: 8
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private addMeteredDatapoints(baseName String, metered Metered, dataPoints List<IMetricsConsumer.DataPoint>) : void extracted from private processTimers(taskId int, dataPoints List<IMetricsConsumer.DataPoint>) : void in class org.apache.storm.executor.Executor
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e83fafcb884f4c630dbbe4a8656a4f93a41abe5b/storm-client/src/jvm/org/apache/storm/executor/Executor.java
REFACTORING URL: https://github.com/apache/storm/blob/e83fafcb884f4c630dbbe4a8656a4f93a41abe5b/storm-client/src/jvm/org/apache/storm/executor/Executor.java#L413
DIRECTLY EXTRACTED OPERATION:
        IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(baseName + ".count", metered.getCount());
        dataPoints.add(dataPoint);
        addConvertedMetric(baseName, ".m1_rate", metered.getOneMinuteRate(), dataPoints);
        addConvertedMetric(baseName, ".m5_rate", metered.getFiveMinuteRate(), dataPoints);
        addConvertedMetric(baseName, ".m15_rate", metered.getFifteenMinuteRate(), dataPoints);
        addConvertedMetric(baseName, ".mean_rate", metered.getMeanRate(), dataPoints);
    }

PARAMS COUNT: 3
IS VOID METHOD: true
FRAGMENT LENGTH: 525
FRAGMENT LINE AVG SIZE: 65.625
DEPTHS:
1 2 2 2 2 2 1 1 
AREA: 13
AVG DEPTH: 1.625
NUMBER OF LINES IN FRAGMENT: 8
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 013654d9cb415c4119d2bdf753351f5af5394fad
URL: https://github.com/apache/storm/commit/013654d9cb415c4119d2bdf753351f5af5394fad
DESCRIPTION: Extract Method	private orderExecutorsDefault(td TopologyDetails, unassignedExecutors Collection<ExecutorDetails>) : List<ExecutorDetails> extracted from protected orderExecutors(td TopologyDetails, unassignedExecutors Collection<ExecutorDetails>) : List<ExecutorDetails> in class org.apache.storm.scheduler.resource.strategies.scheduling.BaseResourceAwareStrategy
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/013654d9cb415c4119d2bdf753351f5af5394fad/storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/BaseResourceAwareStrategy.java
REFACTORING URL: https://github.com/apache/storm/blob/013654d9cb415c4119d2bdf753351f5af5394fad/storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/BaseResourceAwareStrategy.java#L530
DIRECTLY EXTRACTED OPERATION:
     * Order executors based on how many in and out connections it will potentially need to make, in descending order. First order
     * components by the number of in and out connections it will have.  Then iterate through the sorted list of components. For each
     * component sort the neighbors of that component by how many connections it will have to make with that component. Add an executor from
     * this component and then from each neighboring component in sorted order. Do this until there is nothing left to schedule.
     *
     * @param td                  The topology the executors belong to
     * @param unassignedExecutors a collection of unassigned executors that need to be assigned. Should only try to assign executors from
     *                            this list
     * @return a list of executors in sorted order
     */
    private List<ExecutorDetails> orderExecutorsDefault(
        TopologyDetails td, Collection<ExecutorDetails> unassignedExecutors) {
        Map<String, Component> componentMap = td.getComponents();
        List<ExecutorDetails> execsScheduled = new LinkedList<>();

        Map<String, Queue<ExecutorDetails>> compToExecsToSchedule = new HashMap<>();
        for (Component component : componentMap.values()) {
            compToExecsToSchedule.put(component.getId(), new LinkedList<>());
            for (ExecutorDetails exec : component.getExecs()) {
                if (unassignedExecutors.contains(exec)) {
                    compToExecsToSchedule.get(component.getId()).add(exec);
                }
            }
        }

        Set<Component> sortedComponents = sortComponents(componentMap);
        sortedComponents.addAll(componentMap.values());

        for (Component currComp : sortedComponents) {
            Map<String, Component> neighbors = new HashMap<>();
            for (String compId : Sets.union(currComp.getChildren(), currComp.getParents())) {
                neighbors.put(compId, componentMap.get(compId));
            }
            Set<Component> sortedNeighbors = sortNeighbors(currComp, neighbors);
            Queue<ExecutorDetails> currCompExesToSched = compToExecsToSchedule.get(currComp.getId());

            boolean flag = false;
            do {
                flag = false;
                if (!currCompExesToSched.isEmpty()) {
                    execsScheduled.add(currCompExesToSched.poll());
                    flag = true;
                }

                for (Component neighborComp : sortedNeighbors) {
                    Queue<ExecutorDetails> neighborCompExesToSched =
                        compToExecsToSchedule.get(neighborComp.getId());
                    if (!neighborCompExesToSched.isEmpty()) {
                        execsScheduled.add(neighborCompExesToSched.poll());
                        flag = true;
                    }
                }
            } while (flag);
        }
        return execsScheduled;
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 2945
FRAGMENT LINE AVG SIZE: 51.666666666666664
DEPTHS:
0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 3 3 4 5 4 3 2 2 2 2 2 2 3 3 4 3 3 3 3 3 3 4 4 5 5 4 4 4 5 5 5 6 6 5 4 3 2 2 1 1 
AREA: 158
AVG DEPTH: 2.7719298245614037
NUMBER OF LINES IN FRAGMENT: 57
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 6976624228386c25e9ac6dd2b8ef87a9deeb1ad9
URL: https://github.com/apache/storm/commit/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9
DESCRIPTION: Extract Method	private processGauges(taskId int, dataPoints List<IMetricsConsumer.DataPoint>) : void extracted from private addV2Metrics(dataPoints List<IMetricsConsumer.DataPoint>) : void in class org.apache.storm.executor.Executor
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java
REFACTORING URL: https://github.com/apache/storm/blob/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java#L347
DIRECTLY EXTRACTED OPERATION:
        Map<String, Gauge> gauges = workerData.getMetricRegistry().getTaskGauges(taskId);
        for (Map.Entry<String, Gauge> entry : gauges.entrySet()) {
            Object v = entry.getValue().getValue();
            if (v instanceof Number) {
                IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(entry.getKey(), v);
                dataPoints.add(dataPoint);
            }
        }
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 428
FRAGMENT LINE AVG SIZE: 42.8
DEPTHS:
1 2 3 3 4 4 3 2 1 1 
AREA: 24
AVG DEPTH: 2.4
NUMBER OF LINES IN FRAGMENT: 10
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private processCounters(taskId int, dataPoints List<IMetricsConsumer.DataPoint>) : void extracted from private addV2Metrics(dataPoints List<IMetricsConsumer.DataPoint>) : void in class org.apache.storm.executor.Executor
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java
REFACTORING URL: https://github.com/apache/storm/blob/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java#L358
DIRECTLY EXTRACTED OPERATION:
        Map<String, Counter> counters = workerData.getMetricRegistry().getTaskCounters(taskId);
        for (Map.Entry<String, Counter> entry : counters.entrySet()) {
            Object value = entry.getValue().getCount();
            IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(entry.getKey(), value);
            dataPoints.add(dataPoint);
        }
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 385
FRAGMENT LINE AVG SIZE: 48.125
DEPTHS:
1 2 3 3 3 2 1 1 
AREA: 16
AVG DEPTH: 2.0
NUMBER OF LINES IN FRAGMENT: 8
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private processHistograms(taskId int, dataPoints List<IMetricsConsumer.DataPoint>) : void extracted from private addV2Metrics(dataPoints List<IMetricsConsumer.DataPoint>) : void in class org.apache.storm.executor.Executor
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java
REFACTORING URL: https://github.com/apache/storm/blob/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java#L367
DIRECTLY EXTRACTED OPERATION:
        Map<String, Histogram> histograms = workerData.getMetricRegistry().getTaskHistograms(taskId);
        for (Map.Entry<String, Histogram> entry : histograms.entrySet()) {
            Snapshot snapshot =  entry.getValue().getSnapshot();
            addSnapshotDatapoints(entry.getKey(), snapshot, dataPoints);
            IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(entry.getKey() + ".count", entry.getValue().getCount());
            dataPoints.add(dataPoint);
        }
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 510
FRAGMENT LINE AVG SIZE: 56.666666666666664
DEPTHS:
1 2 3 3 3 3 2 1 1 
AREA: 19
AVG DEPTH: 2.111111111111111
NUMBER OF LINES IN FRAGMENT: 9
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private processMeters(taskId int, dataPoints List<IMetricsConsumer.DataPoint>) : void extracted from private addV2Metrics(dataPoints List<IMetricsConsumer.DataPoint>) : void in class org.apache.storm.executor.Executor
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java
REFACTORING URL: https://github.com/apache/storm/blob/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java#L377
DIRECTLY EXTRACTED OPERATION:
        Map<String, Meter> meters = workerData.getMetricRegistry().getTaskMeters(taskId);
        for (Map.Entry<String, Meter> entry : meters.entrySet()) {
            IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(entry.getKey() + ".count", entry.getValue().getCount());
            dataPoints.add(dataPoint);
            addConvertedMetric(entry.getKey(), ".m1_rate", entry.getValue().getOneMinuteRate(), dataPoints);
            addConvertedMetric(entry.getKey(), ".m5_rate", entry.getValue().getFiveMinuteRate(), dataPoints);
            addConvertedMetric(entry.getKey(), ".m15_rate", entry.getValue().getFifteenMinuteRate(), dataPoints);
            addConvertedMetric(entry.getKey(), ".mean_rate", entry.getValue().getMeanRate(), dataPoints);
        }
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 791
FRAGMENT LINE AVG SIZE: 71.9090909090909
DEPTHS:
1 2 3 3 3 3 3 3 2 1 1 
AREA: 25
AVG DEPTH: 2.272727272727273
NUMBER OF LINES IN FRAGMENT: 11
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private processTimers(taskId int, dataPoints List<IMetricsConsumer.DataPoint>) : void extracted from private addV2Metrics(dataPoints List<IMetricsConsumer.DataPoint>) : void in class org.apache.storm.executor.Executor
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java
REFACTORING URL: https://github.com/apache/storm/blob/6976624228386c25e9ac6dd2b8ef87a9deeb1ad9/storm-client/src/jvm/org/apache/storm/executor/Executor.java#L389
DIRECTLY EXTRACTED OPERATION:
        Map<String, Timer> timers = workerData.getMetricRegistry().getTaskTimers(taskId);
        for (Map.Entry<String, Timer> entry : timers.entrySet()) {
            Snapshot snapshot =  entry.getValue().getSnapshot();
            addSnapshotDatapoints(entry.getKey(), snapshot, dataPoints);
            IMetricsConsumer.DataPoint dataPoint = new IMetricsConsumer.DataPoint(entry.getKey() + ".count", entry.getValue().getCount());
            dataPoints.add(dataPoint);
        }
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 490
FRAGMENT LINE AVG SIZE: 54.44444444444444
DEPTHS:
1 2 3 3 3 3 2 1 1 
AREA: 19
AVG DEPTH: 2.111111111111111
NUMBER OF LINES IN FRAGMENT: 9
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 5daf0cce0ddbbb7c6ceee38c5cfec9ba3a858517
URL: https://github.com/apache/storm/commit/5daf0cce0ddbbb7c6ceee38c5cfec9ba3a858517
DESCRIPTION: Extract Method	public getAllAssignmentsFromNumaSupervisors(nimbus Nimbus.Iface, node String) : List<SupervisorAssignments> extracted from public getAssignmentsFromMaster(conf Map, clusterState IStormClusterState, node String) : void in class org.apache.storm.daemon.supervisor.timer.SynchronizeAssignments
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/5daf0cce0ddbbb7c6ceee38c5cfec9ba3a858517/storm-server/src/main/java/org/apache/storm/daemon/supervisor/timer/SynchronizeAssignments.java
REFACTORING URL: https://github.com/apache/storm/blob/5daf0cce0ddbbb7c6ceee38c5cfec9ba3a858517/storm-server/src/main/java/org/apache/storm/daemon/supervisor/timer/SynchronizeAssignments.java#L116
DIRECTLY EXTRACTED OPERATION:
            Nimbus.Iface nimbus, String node
    ) throws TException {
        List<SupervisorAssignments> supervisorAssignmentsList = new ArrayList();
        Map<String, Object> validatedNumaMap = SupervisorUtils.getNumaMap(supervisor.getConf());
        for (Map.Entry<String, Object> numaEntry : validatedNumaMap.entrySet()) {
            String numaId = numaEntry.getKey();
            SupervisorAssignments assignments = nimbus.getSupervisorAssignments(
                    node + ServerConstants.NUMA_ID_SEPARATOR + numaId
            );
            supervisorAssignmentsList.add(assignments);
        }
        SupervisorAssignments assignments = nimbus.getSupervisorAssignments(node);
        supervisorAssignmentsList.add(assignments);

        return supervisorAssignmentsList;
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 796
FRAGMENT LINE AVG SIZE: 46.8235294117647
DEPTHS:
0 1 2 2 2 3 3 3 3 3 2 2 2 2 2 1 1 
AREA: 34
AVG DEPTH: 2.0
NUMBER OF LINES IN FRAGMENT: 17
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: ef9ab9cc379af1f45fd2d0994a51ad759bdbeffc
URL: https://github.com/apache/storm/commit/ef9ab9cc379af1f45fd2d0994a51ad759bdbeffc
DESCRIPTION: Extract Method	private readFromStream(is InputStream) : String extracted from public processScript(conf Map<String,Object>, script String) : String in class org.apache.storm.healthcheck.HealthChecker
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/ef9ab9cc379af1f45fd2d0994a51ad759bdbeffc/storm-server/src/main/java/org/apache/storm/healthcheck/HealthChecker.java
REFACTORING URL: https://github.com/apache/storm/blob/ef9ab9cc379af1f45fd2d0994a51ad759bdbeffc/storm-server/src/main/java/org/apache/storm/healthcheck/HealthChecker.java#L150
DIRECTLY EXTRACTED OPERATION:
        StringBuilder stringBuilder = new StringBuilder();
        try (BufferedReader reader = new BufferedReader(new InputStreamReader(is))) {
            String str;
            while ((str = reader.readLine()) != null) {
                stringBuilder.append(str).append("\n");
            }
        }
        return stringBuilder.toString().trim();
    }
}
PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 361
FRAGMENT LINE AVG SIZE: 36.1
DEPTHS:
1 2 3 3 4 3 2 2 1 0 
AREA: 21
AVG DEPTH: 2.1
NUMBER OF LINES IN FRAGMENT: 10
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: fb78f00849474392269137b190390a210826259f
URL: https://github.com/apache/storm/commit/fb78f00849474392269137b190390a210826259f
DESCRIPTION: Extract Method	private createConf() : Map<String,Object> extracted from private mockContext(availableTaskIds List<Integer>) : WorkerTopologyContext in class org.apache.storm.grouping.LoadAwareShuffleGroupingTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/fb78f00849474392269137b190390a210826259f/storm-client/test/jvm/org/apache/storm/grouping/LoadAwareShuffleGroupingTest.java
REFACTORING URL: https://github.com/apache/storm/blob/fb78f00849474392269137b190390a210826259f/storm-client/test/jvm/org/apache/storm/grouping/LoadAwareShuffleGroupingTest.java#L54
DIRECTLY EXTRACTED OPERATION:
        Map<String, Object> conf = new HashMap<>();
        conf.put(Config.STORM_NETWORK_TOPOGRAPHY_PLUGIN, "org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping");
        conf.put(Config.TOPOLOGY_LOCALITYAWARE_HIGHER_BOUND, 0.8);
        conf.put(Config.TOPOLOGY_LOCALITYAWARE_LOWER_BOUND, 0.2);
        return conf;
    }

IS VOID METHOD: false
FRAGMENT LENGTH: 339
FRAGMENT LINE AVG SIZE: 48.42857142857143
DEPTHS:
1 2 2 2 2 1 1 
AREA: 11
AVG DEPTH: 1.5714285714285714
NUMBER OF LINES IN FRAGMENT: 7
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 1137f61aad3e277f102fb8baf6ee24a5d183da32
URL: https://github.com/apache/storm/commit/1137f61aad3e277f102fb8baf6ee24a5d183da32
DESCRIPTION: Extract Method	public makeTestTopoConf(maxCoLocationCnt int) : Map<String,Object> extracted from public makeTestTopoConf() : Map<String,Object> in class org.apache.storm.scheduler.resource.strategies.scheduling.TestConstraintSolverStrategy
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/1137f61aad3e277f102fb8baf6ee24a5d183da32/storm-server/src/test/java/org/apache/storm/scheduler/resource/strategies/scheduling/TestConstraintSolverStrategy.java
REFACTORING URL: https://github.com/apache/storm/blob/1137f61aad3e277f102fb8baf6ee24a5d183da32/storm-server/src/test/java/org/apache/storm/scheduler/resource/strategies/scheduling/TestConstraintSolverStrategy.java#L98
DIRECTLY EXTRACTED OPERATION:
     * Make test Topology configuration, but with the newer spread constraints that allow associating a number
     * with the spread. This number represents the maximum co-located component count. Default under the old
     * configuration is assumed to be 1.
     *
     * @param maxCoLocationCnt Maximum co-located component (spout-0), minimum value is 1.
     * @return
     */
    public Map<String, Object> makeTestTopoConf(int maxCoLocationCnt) {
        if (maxCoLocationCnt < 1) {
            maxCoLocationCnt = 1;
        }
        List<List<String>> constraints = new LinkedList<>();
        addConstraints("spout-0", "bolt-0", constraints);
        addConstraints("bolt-2", "spout-0", constraints);
        addConstraints("bolt-1", "bolt-2", constraints);
        addConstraints("bolt-1", "bolt-0", constraints);
        addConstraints("bolt-1", "spout-0", constraints);

        Map<String, Integer> spreads = new HashMap<>();
        spreads.put("spout-0", maxCoLocationCnt);

        Map<String, Object> config = Utils.readDefaultConfig();

        setConstraintConfig(constraints, spreads, config);

        config.put(DaemonConfig.RESOURCE_AWARE_SCHEDULER_MAX_STATE_SEARCH, MAX_TRAVERSAL_DEPTH);
        config.put(Config.TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH, MAX_TRAVERSAL_DEPTH);
        config.put(Config.TOPOLOGY_WORKER_MAX_HEAP_SIZE_MB, 100_000);
        config.put(Config.TOPOLOGY_PRIORITY, 1);
        config.put(Config.TOPOLOGY_COMPONENT_CPU_PCORE_PERCENT, 10);
        config.put(Config.TOPOLOGY_COMPONENT_RESOURCES_ONHEAP_MEMORY_MB, 100);
        config.put(Config.TOPOLOGY_COMPONENT_RESOURCES_OFFHEAP_MEMORY_MB, 0.0);

        return config;
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 1681
FRAGMENT LINE AVG SIZE: 46.69444444444444
DEPTHS:
0 1 1 1 1 1 1 1 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 
AREA: 62
AVG DEPTH: 1.7222222222222223
NUMBER OF LINES IN FRAGMENT: 36
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: d74a712560a4a61f01261e6d14f80d3a4b720af6
URL: https://github.com/apache/storm/commit/d74a712560a4a61f01261e6d14f80d3a4b720af6
DESCRIPTION: Extract Method	public getHdfsPrincipal(conf Map<String,Object>) : String extracted from public getBlobstoreHDFSPrincipal(conf Map) : String in class org.apache.storm.Config
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/d74a712560a4a61f01261e6d14f80d3a4b720af6/storm-client/src/jvm/org/apache/storm/Config.java
REFACTORING URL: https://github.com/apache/storm/blob/d74a712560a4a61f01261e6d14f80d3a4b720af6/storm-client/src/jvm/org/apache/storm/Config.java#L2014
DIRECTLY EXTRACTED OPERATION:
     * Get the hostname substituted hdfs principal.
     * @param conf the storm Configuration
     * @return the principal
     * @throws UnknownHostException on UnknowHostException
     */
    public static String getHdfsPrincipal(Map<String, Object> conf) throws UnknownHostException {
        String ret;

        String blobstorePrincipal = (String) conf.get(Config.BLOBSTORE_HDFS_PRINCIPAL);
        String hdfsPrincipal = (String) conf.get(Config.STORM_HDFS_LOGIN_PRINCIPAL);
        if (blobstorePrincipal == null && hdfsPrincipal == null) {
            return null;
        } else if (blobstorePrincipal == null) {
            ret = hdfsPrincipal;
        } else if (hdfsPrincipal == null) {
            LOG.warn("{} is used as the hdfs principal. Please use {} instead",
                Config.BLOBSTORE_HDFS_PRINCIPAL, Config.STORM_HDFS_LOGIN_PRINCIPAL);
            ret = blobstorePrincipal;
        } else {
            //both not null;
            LOG.warn("Both {} and {} are set. Use {} only.",
                Config.BLOBSTORE_HDFS_PRINCIPAL, Config.STORM_HDFS_LOGIN_PRINCIPAL, Config.STORM_HDFS_LOGIN_PRINCIPAL);
            ret = hdfsPrincipal;
        }
        return substituteHostnameInPrincipal(ret);
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 1232
FRAGMENT LINE AVG SIZE: 45.629629629629626
DEPTHS:
0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 2 2 1 1 
AREA: 57
AVG DEPTH: 2.111111111111111
NUMBER OF LINES IN FRAGMENT: 27
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 6338cc9394523ea490128484deda72b51a09ddcb
URL: https://github.com/apache/storm/commit/6338cc9394523ea490128484deda72b51a09ddcb
DESCRIPTION: Extract Method	public getJaasConf(topoConf Map<String,Object>) : String extracted from public getConfiguration(topoConf Map<String,Object>) : Configuration in class org.apache.storm.security.auth.ClientAuthUtils
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/6338cc9394523ea490128484deda72b51a09ddcb/storm-client/src/jvm/org/apache/storm/security/auth/ClientAuthUtils.java
REFACTORING URL: https://github.com/apache/storm/blob/6338cc9394523ea490128484deda72b51a09ddcb/storm-client/src/jvm/org/apache/storm/security/auth/ClientAuthUtils.java#L63
DIRECTLY EXTRACTED OPERATION:
        return (String) topoConf.get("java.security.auth.login.config");
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 80
FRAGMENT LINE AVG SIZE: 26.666666666666668
DEPTHS:
1 1 1 
AREA: 3
AVG DEPTH: 1.0
NUMBER OF LINES IN FRAGMENT: 3
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 073987bc681c2169adb182465081dd3494599bbc
URL: https://github.com/apache/storm/commit/073987bc681c2169adb182465081dd3494599bbc
DESCRIPTION: Extract Method	private areAnyOverZero(skipCpuCheck boolean) : boolean extracted from public areAnyOverZero() : boolean in class org.apache.storm.scheduler.resource.normalization.NormalizedResources
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/073987bc681c2169adb182465081dd3494599bbc/storm-server/src/main/java/org/apache/storm/scheduler/resource/normalization/NormalizedResources.java
REFACTORING URL: https://github.com/apache/storm/blob/073987bc681c2169adb182465081dd3494599bbc/storm-server/src/main/java/org/apache/storm/scheduler/resource/normalization/NormalizedResources.java#L409
DIRECTLY EXTRACTED OPERATION:
        for (int i = 0; i < otherResources.length; i++) {
            if (otherResources[i] > 0) {
                return true;
            }
        }
        if (skipCpuCheck) {
            return false;
        } else {
            return cpu > 0;
        }
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 268
FRAGMENT LINE AVG SIZE: 22.333333333333332
DEPTHS:
2 3 4 3 2 2 3 3 3 2 1 1 
AREA: 29
AVG DEPTH: 2.4166666666666665
NUMBER OF LINES IN FRAGMENT: 12
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959
URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String) : LocalAssignment extracted from public testRequestDownloadBaseTopologyBlobs() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L331
DIRECTLY EXTRACTED OPERATION:
        return constructLocalAssignment(topoId, owner,
                Collections.singletonList(new ExecutorInfo(1, 1))
        );
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 139
FRAGMENT LINE AVG SIZE: 27.8
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String) : LocalAssignment extracted from public testRequestDownloadTopologyBlobs() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L331
DIRECTLY EXTRACTED OPERATION:
        return constructLocalAssignment(topoId, owner,
                Collections.singletonList(new ExecutorInfo(1, 1))
        );
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 139
FRAGMENT LINE AVG SIZE: 27.8
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String) : LocalAssignment extracted from public testRequestDownloadTopologyBlobsLocalMode() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L331
DIRECTLY EXTRACTED OPERATION:
        return constructLocalAssignment(topoId, owner,
                Collections.singletonList(new ExecutorInfo(1, 1))
        );
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 139
FRAGMENT LINE AVG SIZE: 27.8
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testReconstruct() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testArchives(archiveFile File, supportSymlinks boolean, size int) : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testBasic() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testMultipleKeysOneUser() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testFailAcls() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testMultipleUsers() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testMultipleUsers() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testMultipleUsers() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testUpdate() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructLocalAssignment(topoId String, owner String, executorInfos List<ExecutorInfo>) : LocalAssignment extracted from public testUpdate() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L337
DIRECTLY EXTRACTED OPERATION:
        LocalAssignment assignment = new LocalAssignment(topoId, executorInfos);
        assignment.set_owner(owner);
        return assignment;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 152
FRAGMENT LINE AVG SIZE: 30.4
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructEmptyStormTopology() : StormTopology extracted from public testRequestDownloadTopologyBlobs() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L343
DIRECTLY EXTRACTED OPERATION:
        StormTopology topology = new StormTopology();
        topology.set_spouts(new HashMap<>());
        topology.set_bolts(new HashMap<>());
        topology.set_state_spouts(new HashMap<>());
        return topology;
    }

IS VOID METHOD: false
FRAGMENT LENGTH: 229
FRAGMENT LINE AVG SIZE: 32.714285714285715
DEPTHS:
1 2 2 2 2 1 1 
AREA: 11
AVG DEPTH: 1.5714285714285714
NUMBER OF LINES IN FRAGMENT: 7
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private constructEmptyStormTopology() : StormTopology extracted from public testRequestDownloadTopologyBlobsLocalMode() : void in class org.apache.storm.localizer.AsyncLocalizerTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java
REFACTORING URL: https://github.com/apache/storm/blob/74958a6e333b9f4bbf8ccb26aeab8fc47b2d2959/storm-server/src/test/java/org/apache/storm/localizer/AsyncLocalizerTest.java#L343
DIRECTLY EXTRACTED OPERATION:
        StormTopology topology = new StormTopology();
        topology.set_spouts(new HashMap<>());
        topology.set_bolts(new HashMap<>());
        topology.set_state_spouts(new HashMap<>());
        return topology;
    }

IS VOID METHOD: false
FRAGMENT LENGTH: 229
FRAGMENT LINE AVG SIZE: 32.714285714285715
DEPTHS:
1 2 2 2 2 1 1 
AREA: 11
AVG DEPTH: 1.5714285714285714
NUMBER OF LINES IN FRAGMENT: 7
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: ab1c8b0838e7006d2443f67dbde907244faf8e96
URL: https://github.com/apache/storm/commit/ab1c8b0838e7006d2443f67dbde907244faf8e96
DESCRIPTION: Extract Method	public makeCluster(topologies Topologies, supMap Map<String,SupervisorDetails>) : Cluster extracted from public testIntegrationWithRAS() : void in class org.apache.storm.scheduler.resource.strategies.scheduling.TestConstraintSolverStrategy
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/ab1c8b0838e7006d2443f67dbde907244faf8e96/storm-server/src/test/java/org/apache/storm/scheduler/resource/strategies/scheduling/TestConstraintSolverStrategy.java
REFACTORING URL: https://github.com/apache/storm/blob/ab1c8b0838e7006d2443f67dbde907244faf8e96/storm-server/src/test/java/org/apache/storm/scheduler/resource/strategies/scheduling/TestConstraintSolverStrategy.java#L94
DIRECTLY EXTRACTED OPERATION:
        if (supMap == null) {
            supMap = genSupervisors(4, 2, 120, 1200);
        }
        Map<String, Object> config = Utils.readDefaultConfig();
        return new Cluster(new INimbusTest(), new ResourceMetrics(new StormMetricsRegistry()), supMap, new HashMap<>(), topologies, config);
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 306
FRAGMENT LINE AVG SIZE: 43.714285714285715
DEPTHS:
2 3 2 2 2 1 1 
AREA: 13
AVG DEPTH: 1.8571428571428572
NUMBER OF LINES IN FRAGMENT: 7
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 90d7c0288d5dfbdeb02e9742d3f9215ce3178e5b
URL: https://github.com/apache/storm/commit/90d7c0288d5dfbdeb02e9742d3f9215ce3178e5b
DESCRIPTION: Extract Method	private getPlaceholderCommonAggregateStats(component Object) : CommonAggregateStats extracted from private maybeAddPlaceholderSpoutAggStats(topoPageInfo TopologyPageInfo, topology StormTopology) : void in class org.apache.storm.daemon.nimbus.Nimbus
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/90d7c0288d5dfbdeb02e9742d3f9215ce3178e5b/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java
REFACTORING URL: https://github.com/apache/storm/blob/90d7c0288d5dfbdeb02e9742d3f9215ce3178e5b/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L4206
DIRECTLY EXTRACTED OPERATION:
        // common aggregate
        CommonAggregateStats commonStats = new CommonAggregateStats();

        // get num_executors
        int numExecutors = 0;
        try {
            numExecutors = StormCommon.numStartExecutors(component);
        } catch (InvalidTopologyException e) {
            // ignore
        }

        // get num_tasks
        Map<String, Object> jsonMap = StormCommon.componentConf(component);
        int numTasks = ObjectReader.getInt(jsonMap.getOrDefault(Config.TOPOLOGY_TASKS, numExecutors));

        commonStats.set_num_executors(numExecutors);
        commonStats.set_num_tasks(numTasks);
        commonStats.set_emitted(0);
        commonStats.set_transferred(0);
        commonStats.set_acked(0);

        return commonStats;
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 771
FRAGMENT LINE AVG SIZE: 32.125
DEPTHS:
1 2 2 2 2 2 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 
AREA: 48
AVG DEPTH: 2.0
NUMBER OF LINES IN FRAGMENT: 24
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private getPlaceholderCommonAggregateStats(component Object) : CommonAggregateStats extracted from private maybeAddPlaceholderBoltAggStats(topoPageInfo TopologyPageInfo, topology StormTopology, includeSys boolean) : void in class org.apache.storm.daemon.nimbus.Nimbus
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/90d7c0288d5dfbdeb02e9742d3f9215ce3178e5b/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java
REFACTORING URL: https://github.com/apache/storm/blob/90d7c0288d5dfbdeb02e9742d3f9215ce3178e5b/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L4206
DIRECTLY EXTRACTED OPERATION:
        // common aggregate
        CommonAggregateStats commonStats = new CommonAggregateStats();

        // get num_executors
        int numExecutors = 0;
        try {
            numExecutors = StormCommon.numStartExecutors(component);
        } catch (InvalidTopologyException e) {
            // ignore
        }

        // get num_tasks
        Map<String, Object> jsonMap = StormCommon.componentConf(component);
        int numTasks = ObjectReader.getInt(jsonMap.getOrDefault(Config.TOPOLOGY_TASKS, numExecutors));

        commonStats.set_num_executors(numExecutors);
        commonStats.set_num_tasks(numTasks);
        commonStats.set_emitted(0);
        commonStats.set_transferred(0);
        commonStats.set_acked(0);

        return commonStats;
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 771
FRAGMENT LINE AVG SIZE: 32.125
DEPTHS:
1 2 2 2 2 2 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 
AREA: 48
AVG DEPTH: 2.0
NUMBER OF LINES IN FRAGMENT: 24
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 14530099b2accd462f3af815eee82d3d1b407c0a
URL: https://github.com/apache/storm/commit/14530099b2accd462f3af815eee82d3d1b407c0a
DESCRIPTION: Extract Method	private createEmitter(kafkaConsumer Consumer<String,String>, firstPollOffsetStrategy FirstPollOffsetStrategy) : KafkaTridentSpoutEmitter<String,String> extracted from private createEmitter(firstPollOffsetStrategy FirstPollOffsetStrategy) : KafkaTridentSpoutEmitter<String,String> in class org.apache.storm.kafka.spout.trident.KafkaTridentSpoutEmitterEmitTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/14530099b2accd462f3af815eee82d3d1b407c0a/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitterEmitTest.java
REFACTORING URL: https://github.com/apache/storm/blob/14530099b2accd462f3af815eee82d3d1b407c0a/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitterEmitTest.java#L92
DIRECTLY EXTRACTED OPERATION:
        return new KafkaTridentSpoutEmitter<>(
                SingleTopicKafkaTridentSpoutConfiguration.createKafkaSpoutConfigBuilder(-1)
                        .setRecordTranslator(r -> new Values(r.offset()), new Fields("offset"))
                        .setFirstPollOffsetStrategy(firstPollOffsetStrategy)
                        .setPollTimeoutMs(1)
                        .setStartTimeStamp(startTimeStamp)
                        .build(),
                topologyContextMock,
                config -> kafkaConsumer, new TopicAssigner());
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 557
FRAGMENT LINE AVG SIZE: 50.63636363636363
DEPTHS:
1 2 2 2 2 2 2 2 2 1 1 
AREA: 19
AVG DEPTH: 1.7272727272727273
NUMBER OF LINES IN FRAGMENT: 11
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 7eec29fc80b7c2e48137486bbeb65a18e35f648e
URL: https://github.com/apache/storm/commit/7eec29fc80b7c2e48137486bbeb65a18e35f648e
DESCRIPTION: Extract Method	public couldHoldIgnoringSharedMemoryAndCpu(other NormalizedResources, thisTotalMemoryMb double, otherTotalMemoryMb double) : boolean extracted from public couldHoldIgnoringSharedMemory(other NormalizedResources, thisTotalMemoryMb double, otherTotalMemoryMb double) : boolean in class org.apache.storm.scheduler.resource.normalization.NormalizedResources
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/7eec29fc80b7c2e48137486bbeb65a18e35f648e/storm-server/src/main/java/org/apache/storm/scheduler/resource/normalization/NormalizedResources.java
REFACTORING URL: https://github.com/apache/storm/blob/7eec29fc80b7c2e48137486bbeb65a18e35f648e/storm-server/src/main/java/org/apache/storm/scheduler/resource/normalization/NormalizedResources.java#L216
DIRECTLY EXTRACTED OPERATION:
     * A simple sanity check to see if all of the resources in this would be large enough to hold the resources in other ignoring memory. It
     * does not check memory because with shared memory it is beyond the scope of this.  It also does not check CPU.
     *
     * @param other              the resources that we want to check if they would fit in this.
     * @param thisTotalMemoryMb  The total memory in MB of this
     * @param otherTotalMemoryMb The total memory in MB of other
     * @return true if it might fit, else false if it could not possibly fit.
     */
    public boolean couldHoldIgnoringSharedMemoryAndCpu(NormalizedResources other, double thisTotalMemoryMb, double otherTotalMemoryMb) {
        int length = Math.max(this.otherResources.length, other.otherResources.length);
        for (int i = 0; i < length; i++) {
            if (getResourceAt(i) < other.getResourceAt(i)) {
                return false;
            }
        }

        return thisTotalMemoryMb >= otherTotalMemoryMb;
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 1023
FRAGMENT LINE AVG SIZE: 53.8421052631579
DEPTHS:
0 1 1 1 1 1 1 1 1 2 2 3 4 3 2 2 2 1 1 
AREA: 30
AVG DEPTH: 1.5789473684210527
NUMBER OF LINES IN FRAGMENT: 19
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 27921e208a1373f4f3d8b1639693510e23cb593b
URL: https://github.com/apache/storm/commit/27921e208a1373f4f3d8b1639693510e23cb593b
DESCRIPTION: Extract Method	public createDefaultUncaughtExceptionHandler() : UncaughtExceptionHandler extracted from public setupDefaultUncaughtExceptionHandler() : void in class org.apache.storm.utils.Utils
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/27921e208a1373f4f3d8b1639693510e23cb593b/storm-client/src/jvm/org/apache/storm/utils/Utils.java
REFACTORING URL: https://github.com/apache/storm/blob/27921e208a1373f4f3d8b1639693510e23cb593b/storm-client/src/jvm/org/apache/storm/utils/Utils.java#L979
DIRECTLY EXTRACTED OPERATION:
        return (thread, thrown) -> {
            try {
                handleUncaughtException(thrown);
            } catch (Error err) {
                LOG.error("Received error in thread {}.. terminating server...", thread.getName(), err);
                Runtime.getRuntime().exit(-2);
            }
        };
    }
    
IS VOID METHOD: false
FRAGMENT LENGTH: 326
FRAGMENT LINE AVG SIZE: 32.6
DEPTHS:
1 2 3 3 3 3 2 1 0 0 
AREA: 18
AVG DEPTH: 1.8
NUMBER OF LINES IN FRAGMENT: 10
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 947c7b22acf4cdf4f95001b26e700a590d675220
URL: https://github.com/apache/storm/commit/947c7b22acf4cdf4f95001b26e700a590d675220
DESCRIPTION: Extract Method	private informAllOfChangeAndWaitForConsensus() : CompletableFuture<Void> extracted from public informAllOfChangeAndWaitForConsensus() : void in class org.apache.storm.localizer.LocallyCachedBlob
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/947c7b22acf4cdf4f95001b26e700a590d675220/storm-server/src/main/java/org/apache/storm/localizer/LocallyCachedBlob.java
REFACTORING URL: https://github.com/apache/storm/blob/947c7b22acf4cdf4f95001b26e700a590d675220/storm-server/src/main/java/org/apache/storm/localizer/LocallyCachedBlob.java#L255
DIRECTLY EXTRACTED OPERATION:
     * Inform all of the callbacks that a change is going to happen and then wait for
     * them to all get back that it is OK to make that change.
     * 
     * @return A future to complete when the change is committed
     */
    private CompletableFuture<Void> informAllOfChangeAndWaitForConsensus() {
        HashMap<PortAndAssignment, BlobChangingCallback> refsCopy = new HashMap<>(references);
        CountDownLatch cdl = new CountDownLatch(refsCopy.size());
        CompletableFuture<Void> doneUpdating = new CompletableFuture<>();
        for (Map.Entry<PortAndAssignment, BlobChangingCallback> entry : refsCopy.entrySet()) {
            GoodToGo gtg = new GoodToGo(cdl, doneUpdating);
            try {
                PortAndAssignment pna = entry.getKey();
                BlobChangingCallback cb = entry.getValue();
                cb.blobChanging(pna.getAssignment(), pna.getPort(), this, gtg);
            } finally {
                gtg.countDownIfLatchWasNotGotten();
            }
        }
        try {
            cdl.await(3, TimeUnit.MINUTES);
        } catch (InterruptedException e) {
            //Interrupted is thrown when we are shutting down.
            // So just ignore it for now...
        }
        return doneUpdating;
    }

IS VOID METHOD: false
FRAGMENT LENGTH: 1265
FRAGMENT LINE AVG SIZE: 45.17857142857143
DEPTHS:
0 1 1 1 1 1 2 2 2 2 3 3 4 4 4 4 4 3 2 2 3 3 3 3 2 2 1 1 
AREA: 64
AVG DEPTH: 2.2857142857142856
NUMBER OF LINES IN FRAGMENT: 28
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: e909b3d604367e7c47c3bbf3ec8e7f6b672ff778
URL: https://github.com/apache/storm/commit/e909b3d604367e7c47c3bbf3ec8e7f6b672ff778
DESCRIPTION: Extract Method	private searchLogFileNotFound(callback String) : Response extracted from public searchLogFile(fileName String, user String, isDaemon boolean, search String, numMatchesStr String, offsetStr String, callback String, origin String) : Response in class org.apache.storm.daemon.logviewer.handler.LogviewerLogSearchHandler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e909b3d604367e7c47c3bbf3ec8e7f6b672ff778/storm-webapp/src/main/java/org/apache/storm/daemon/logviewer/handler/LogviewerLogSearchHandler.java
REFACTORING URL: https://github.com/apache/storm/blob/e909b3d604367e7c47c3bbf3ec8e7f6b672ff778/storm-webapp/src/main/java/org/apache/storm/daemon/logviewer/handler/LogviewerLogSearchHandler.java#L200
DIRECTLY EXTRACTED OPERATION:
        Map<String, String> entity = new HashMap<>();
        entity.put("error", "Not Found");
        entity.put("errorMessage", "The file was not found on this node.");

        return new JsonResponseBuilder().setData(entity).setCallback(callback).setStatus(404).build();
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 283
FRAGMENT LINE AVG SIZE: 40.42857142857143
DEPTHS:
1 2 2 2 2 1 1 
AREA: 11
AVG DEPTH: 1.5714285714285714
NUMBER OF LINES IN FRAGMENT: 7
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 9df5de6993b347e3b0ca3b18da35271022ad8d46
URL: https://github.com/apache/storm/commit/9df5de6993b347e3b0ca3b18da35271022ad8d46
DESCRIPTION: Extract Method	package cleanupEmptyTopoDirectory(dir Path) : void extracted from public run() : void in class org.apache.storm.daemon.logviewer.utils.LogCleaner
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/9df5de6993b347e3b0ca3b18da35271022ad8d46/storm-webapp/src/main/java/org/apache/storm/daemon/logviewer/utils/LogCleaner.java
REFACTORING URL: https://github.com/apache/storm/blob/9df5de6993b347e3b0ca3b18da35271022ad8d46/storm-webapp/src/main/java/org/apache/storm/daemon/logviewer/utils/LogCleaner.java#L229
DIRECTLY EXTRACTED OPERATION:
     * Delete the topo dir if it contains zero port dirs.
     */
    @VisibleForTesting
    void cleanupEmptyTopoDirectory(Path dir) throws IOException {
        Path topoDir = dir.getParent();
        try (Stream<Path> topoDirContent = Files.list(topoDir)) {
            if (!topoDirContent.findAny().isPresent()) {
                Utils.forceDelete(topoDir.toAbsolutePath().normalize().toString());
            }
        }
    }

PARAMS COUNT: 1
IS VOID METHOD: true
FRAGMENT LENGTH: 433
FRAGMENT LINE AVG SIZE: 36.083333333333336
DEPTHS:
0 1 1 1 2 2 3 4 3 2 1 1 
AREA: 21
AVG DEPTH: 1.75
NUMBER OF LINES IN FRAGMENT: 12
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 095bdbc267fe4354c28baa84186807dcd3be2a31
URL: https://github.com/apache/storm/commit/095bdbc267fe4354c28baa84186807dcd3be2a31
DESCRIPTION: Extract Method	public withLocalModeOverride(c Callable<T>, ttlSec long, daemonConf Map<String,Object>) : T extracted from public withLocalModeOverride(c Callable<T>, ttlSec long) : T in class org.apache.storm.LocalCluster
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/095bdbc267fe4354c28baa84186807dcd3be2a31/storm-server/src/main/java/org/apache/storm/LocalCluster.java
REFACTORING URL: https://github.com/apache/storm/blob/095bdbc267fe4354c28baa84186807dcd3be2a31/storm-server/src/main/java/org/apache/storm/LocalCluster.java#L316
DIRECTLY EXTRACTED OPERATION:
     * Run c with a local mode cluster overriding the NimbusClient and DRPCClient calls. NOTE local mode override happens by default now
     * unless netty is turned on for the local cluster.
     *
     * @param c      the callable to run in this mode
     * @param ttlSec the number of seconds to let the cluster run after c has completed
     * @param daemonConf configs to set for the daemon processes.
     * @return the result of calling C
     *
     * @throws Exception on any Exception.
     */
    public static <T> T withLocalModeOverride(Callable<T> c, long ttlSec, Map<String, Object> daemonConf) throws Exception {
        LOG.info("\n\n\t\tSTARTING LOCAL MODE CLUSTER\n\n");
        Builder builder = new Builder();
        if (daemonConf != null) {
            builder.withDaemonConf(daemonConf);
        }
        try (LocalCluster local = builder.build();
             LocalDRPC drpc = new LocalDRPC(local.metricRegistry);
             DRPCClient.LocalOverride drpcOverride = new DRPCClient.LocalOverride(drpc)) {

            T ret = c.call();
            LOG.info("\n\n\t\tRUNNING LOCAL CLUSTER for {} seconds.\n\n", ttlSec);
            Thread.sleep(ttlSec * 1000);

            LOG.info("\n\n\t\tSTOPPING LOCAL MODE CLUSTER\n\n");
            return ret;
        }
    }

PARAMS COUNT: 3
IS VOID METHOD: false
FRAGMENT LENGTH: 1295
FRAGMENT LINE AVG SIZE: 44.6551724137931
DEPTHS:
0 1 1 1 1 1 1 1 1 1 1 2 2 2 3 2 2 2 2 3 3 3 3 3 3 3 2 1 1 
AREA: 52
AVG DEPTH: 1.793103448275862
NUMBER OF LINES IN FRAGMENT: 29
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 4bba9c4e8ba962dd6f35c7fd25cfa466050f5607
URL: https://github.com/apache/storm/commit/4bba9c4e8ba962dd6f35c7fd25cfa466050f5607
DESCRIPTION: Extract Method	private getFromClasspath(classpath List<String>, propFileName String) : IVersionInfo extracted from public getFromClasspath(classpath List<String>) : IVersionInfo in class org.apache.storm.utils.VersionInfo
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/4bba9c4e8ba962dd6f35c7fd25cfa466050f5607/storm-client/src/jvm/org/apache/storm/utils/VersionInfo.java
REFACTORING URL: https://github.com/apache/storm/blob/4bba9c4e8ba962dd6f35c7fd25cfa466050f5607/storm-client/src/jvm/org/apache/storm/utils/VersionInfo.java#L134
DIRECTLY EXTRACTED OPERATION:
        IVersionInfo ret = null;
        for (String part: classpath) {
            Path p = Paths.get(part);
            if (Files.isDirectory(p)) {
                Path child = p.resolve(propFileName);
                if (Files.exists(child) && !Files.isDirectory(child)) {
                    try (FileReader reader = new FileReader(child.toFile())) {
                        Properties info = new Properties();
                        info.load(reader);
                        ret = new VersionInfoImpl(info);
                        break;
                    } catch (IOException e) {
                        LOG.error("Skipping {} get an error while trying to parse the file.", part, e);
                    }
                }
            } else if (part.toLowerCase().endsWith(".jar")
                || part.toLowerCase().endsWith(".zip")) {
                //Treat it like a jar
                try (JarFile jf = new JarFile(p.toFile())) {
                    Enumeration<? extends ZipEntry> zipEnums = jf.entries();
                    while (zipEnums.hasMoreElements()) {
                        ZipEntry entry = zipEnums.nextElement();
                        if (!entry.isDirectory() && entry.getName().equals(propFileName)) {
                            try (InputStreamReader reader = new InputStreamReader(jf.getInputStream(entry))) {
                                Properties info = new Properties();
                                info.load(reader);
                                ret = new VersionInfoImpl(info);
                                break;
                            }
                        }
                    }
                } catch (IOException e) {
                    LOG.error("Skipping {} get an error while trying to parse the jar file.", part, e);
                }
            } else {
                LOG.warn("Skipping {} don't know what to do with it.", part);
            }
        }
        return ret;
    }

PARAMS COUNT: 2
IS VOID METHOD: false
FRAGMENT LENGTH: 1969
FRAGMENT LINE AVG SIZE: 48.02439024390244
DEPTHS:
1 2 3 3 4 4 5 6 6 6 6 6 6 5 4 3 3 4 4 5 5 6 6 7 8 8 8 8 7 6 5 5 5 4 4 4 3 2 2 1 1 
AREA: 191
AVG DEPTH: 4.658536585365853
NUMBER OF LINES IN FRAGMENT: 41
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: d7d2c62312d2e3ed73273a88359d1e2f35a0ecbc
URL: https://github.com/apache/storm/commit/d7d2c62312d2e3ed73273a88359d1e2f35a0ecbc
DESCRIPTION: Extract Method	private lockingMkAssignments(existingAssignments Map<String,Assignment>, bases Map<String,StormBase>, scratchTopoId String, assignedTopologyIds List<String>, state IStormClusterState, tds Map<String,TopologyDetails>) : void extracted from private mkAssignments(scratchTopoId String) : void in class org.apache.storm.daemon.nimbus.Nimbus
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/d7d2c62312d2e3ed73273a88359d1e2f35a0ecbc/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java
REFACTORING URL: https://github.com/apache/storm/blob/d7d2c62312d2e3ed73273a88359d1e2f35a0ecbc/storm-server/src/main/java/org/apache/storm/daemon/nimbus/Nimbus.java#L2230
DIRECTLY EXTRACTED OPERATION:
                                      String scratchTopoId, List<String> assignedTopologyIds, IStormClusterState state,
                                      Map<String, TopologyDetails> tds) throws Exception {
        Topologies topologies = new Topologies(tds);

        synchronized (schedLock) {
            Map<String, SchedulerAssignment> newSchedulerAssignments =
                    computeNewSchedulerAssignments(existingAssignments, topologies, bases, scratchTopoId);

            Map<String, Map<List<Long>, List<Object>>> topologyToExecutorToNodePort =
                    computeTopoToExecToNodePort(newSchedulerAssignments, assignedTopologyIds);
            Map<String, Map<WorkerSlot, WorkerResources>> newAssignedWorkerToResources =
                    computeTopoToNodePortToResources(newSchedulerAssignments);
            int nowSecs = Time.currentTimeSecs();
            Map<String, SupervisorDetails> basicSupervisorDetailsMap = basicSupervisorDetailsMap(state);
            //construct the final Assignments by adding start-times etc into it
            Map<String, Assignment> newAssignments = new HashMap<>();
            for (Entry<String, Map<List<Long>, List<Object>>> entry : topologyToExecutorToNodePort.entrySet()) {
                String topoId = entry.getKey();
                Map<List<Long>, List<Object>> execToNodePort = entry.getValue();
                if (execToNodePort == null) {
                    execToNodePort = new HashMap<>();
                }
                Set<String> allNodes = new HashSet<>();
                for (List<Object> nodePort : execToNodePort.values()) {
                    allNodes.add((String) nodePort.get(0));
                }
                Map<String, String> allNodeHost = new HashMap<>();
                Assignment existingAssignment = existingAssignments.get(topoId);
                if (existingAssignment != null) {
                    allNodeHost.putAll(existingAssignment.get_node_host());
                }
                for (String node : allNodes) {
                    String host = inimbus.getHostName(basicSupervisorDetailsMap, node);
                    if (host != null) {
                        allNodeHost.put(node, host);
                    }
                }
                Map<List<Long>, NodeInfo> execNodeInfo = null;
                if (existingAssignment != null) {
                    execNodeInfo = existingAssignment.get_executor_node_port();
                }
                List<List<Long>> reassignExecutors = changedExecutors(execNodeInfo, execToNodePort);
                Map<List<Long>, Long> startTimes = new HashMap<>();
                if (existingAssignment != null) {
                    startTimes.putAll(existingAssignment.get_executor_start_time_secs());
                }
                for (List<Long> id : reassignExecutors) {
                    startTimes.put(id, (long) nowSecs);
                }
                Map<WorkerSlot, WorkerResources> workerToResources = newAssignedWorkerToResources.get(topoId);
                if (workerToResources == null) {
                    workerToResources = new HashMap<>();
                }
                Assignment newAssignment = new Assignment((String) conf.get(Config.STORM_LOCAL_DIR));
                Map<String, String> justAssignedKeys = new HashMap<>(allNodeHost);
                //Modifies justAssignedKeys
                justAssignedKeys.keySet().retainAll(allNodes);
                newAssignment.set_node_host(justAssignedKeys);
                //convert NodePort to NodeInfo (again!!!).
                Map<List<Long>, NodeInfo> execToNodeInfo = new HashMap<>();
                for (Entry<List<Long>, List<Object>> execAndNodePort : execToNodePort.entrySet()) {
                    List<Object> nodePort = execAndNodePort.getValue();
                    NodeInfo ni = new NodeInfo();
                    ni.set_node((String) nodePort.get(0));
                    ni.add_to_port((Long) nodePort.get(1));
                    execToNodeInfo.put(execAndNodePort.getKey(), ni);
                }
                newAssignment.set_executor_node_port(execToNodeInfo);
                newAssignment.set_executor_start_time_secs(startTimes);
                //do another conversion (lets just make this all common)
                Map<NodeInfo, WorkerResources> workerResources = new HashMap<>();
                for (Entry<WorkerSlot, WorkerResources> wr : workerToResources.entrySet()) {
                    WorkerSlot nodePort = wr.getKey();
                    NodeInfo ni = new NodeInfo();
                    ni.set_node(nodePort.getNodeId());
                    ni.add_to_port(nodePort.getPort());
                    WorkerResources resources = wr.getValue();
                    workerResources.put(ni, resources);
                }
                newAssignment.set_worker_resources(workerResources);
                TopologyDetails td = tds.get(topoId);
                newAssignment.set_owner(td.getTopologySubmitter());
                newAssignments.put(topoId, newAssignment);
            }

            boolean assignmentChanged = auditAssignmentChanges(existingAssignments, newAssignments);
            if (assignmentChanged) {
                LOG.debug("RESETTING id->resources and id->worker-resources cache!");
                idToResources.set(new HashMap<>());
                idToWorkerResources.set(new HashMap<>());
            }

            //tasks figure out what tasks to talk to by looking at topology at runtime
            // only log/set when there's been a change to the assignment
            for (Entry<String, Assignment> entry : newAssignments.entrySet()) {
                String topoId = entry.getKey();
                Assignment assignment = entry.getValue();
                Assignment existingAssignment = existingAssignments.get(topoId);
                TopologyDetails td = topologies.getById(topoId);
                if (assignment.equals(existingAssignment)) {
                    LOG.debug("Assignment for {} hasn't changed", topoId);
                } else {
                    LOG.info("Setting new assignment for topology id {}: {}", topoId, assignment);
                    state.setAssignment(topoId, assignment, td.getConf());
                }
            }

            //grouping assignment by node to see the nodes diff, then notify nodes/supervisors to synchronize its owned assignment
            //because the number of existing assignments is small for every scheduling round,
            //we expect to notify supervisors at almost the same time
            Map<String, String> totalAssignmentsChangedNodes = new HashMap<>();
            for (Entry<String, Assignment> entry : newAssignments.entrySet()) {
                String topoId = entry.getKey();
                Assignment assignment = entry.getValue();
                Assignment existingAssignment = existingAssignments.get(topoId);
                totalAssignmentsChangedNodes.putAll(assignmentChangedNodes(existingAssignment, assignment));
            }
            notifySupervisorsAssignments(newAssignments, assignmentsDistributer, totalAssignmentsChangedNodes,
                    basicSupervisorDetailsMap);

            Map<String, Collection<WorkerSlot>> addedSlots = new HashMap<>();
            for (Entry<String, Assignment> entry : newAssignments.entrySet()) {
                String topoId = entry.getKey();
                Assignment assignment = entry.getValue();
                Assignment existingAssignment = existingAssignments.get(topoId);
                if (existingAssignment == null) {
                    existingAssignment = new Assignment();
                    existingAssignment.set_executor_node_port(new HashMap<>());
                    existingAssignment.set_executor_start_time_secs(new HashMap<>());
                }
                Set<WorkerSlot> newSlots = newlyAddedSlots(existingAssignment, assignment);
                addedSlots.put(topoId, newSlots);
            }
            inimbus.assignSlots(topologies, addedSlots);
        }
    }

PARAMS COUNT: 6
IS VOID METHOD: true
FRAGMENT LENGTH: 8093
FRAGMENT LINE AVG SIZE: 59.07299270072993
DEPTHS:
0 1 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 5 4 4 4 5 4 4 4 4 5 4 4 5 5 6 5 4 4 4 5 4 4 4 4 5 4 4 5 4 4 4 5 4 4 4 4 4 4 4 4 4 5 5 5 5 5 4 4 4 4 4 4 5 5 5 5 5 5 4 4 4 4 4 3 3 3 3 4 4 4 3 3 3 3 3 4 4 4 4 4 5 5 5 5 4 3 3 3 3 3 3 3 4 4 4 4 3 3 3 3 3 3 4 4 4 4 5 5 5 4 4 4 3 3 2 1 1 
AREA: 521
AVG DEPTH: 3.802919708029197
NUMBER OF LINES IN FRAGMENT: 137
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 1f1fb0a129a2bbf3a5065af08fc28e309612dea6
URL: https://github.com/apache/storm/commit/1f1fb0a129a2bbf3a5065af08fc28e309612dea6
DESCRIPTION: Extract Method	private toJsonStruct(info IVersionInfo) : Map<String,String> extracted from public getClusterSummary(clusterSummary ClusterSummary, user String, conf Map<String,Object>) : Map<String,Object> in class org.apache.storm.daemon.ui.UIHelpers
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/1f1fb0a129a2bbf3a5065af08fc28e309612dea6/storm-webapp/src/main/java/org/apache/storm/daemon/ui/UIHelpers.java
REFACTORING URL: https://github.com/apache/storm/blob/1f1fb0a129a2bbf3a5065af08fc28e309612dea6/storm-webapp/src/main/java/org/apache/storm/daemon/ui/UIHelpers.java#L528
DIRECTLY EXTRACTED OPERATION:
        Map<String, String> ret = new HashMap<>();
        ret.put("version", info.getVersion());
        ret.put("revision", info.getRevision());
        ret.put("branch", info.getBranch());
        ret.put("date", info.getDate());
        ret.put("user", info.getUser());
        ret.put("url", info.getUrl());
        ret.put("srcChecksum", info.getSrcChecksum());
        return ret;
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 395
FRAGMENT LINE AVG SIZE: 35.90909090909091
DEPTHS:
1 2 2 2 2 2 2 2 2 1 1 
AREA: 19
AVG DEPTH: 1.7272727272727273
NUMBER OF LINES IN FRAGMENT: 11
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private toJsonStruct(info IVersionInfo) : Map<String,String> extracted from public getClusterSummary(clusterSummary ClusterSummary, user String, conf Map<String,Object>) : Map<String,Object> in class org.apache.storm.daemon.ui.UIHelpers
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/1f1fb0a129a2bbf3a5065af08fc28e309612dea6/storm-webapp/src/main/java/org/apache/storm/daemon/ui/UIHelpers.java
REFACTORING URL: https://github.com/apache/storm/blob/1f1fb0a129a2bbf3a5065af08fc28e309612dea6/storm-webapp/src/main/java/org/apache/storm/daemon/ui/UIHelpers.java#L528
DIRECTLY EXTRACTED OPERATION:
        Map<String, String> ret = new HashMap<>();
        ret.put("version", info.getVersion());
        ret.put("revision", info.getRevision());
        ret.put("branch", info.getBranch());
        ret.put("date", info.getDate());
        ret.put("user", info.getUser());
        ret.put("url", info.getUrl());
        ret.put("srcChecksum", info.getSrcChecksum());
        return ret;
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 395
FRAGMENT LINE AVG SIZE: 35.90909090909091
DEPTHS:
1 2 2 2 2 2 2 2 2 1 1 
AREA: 19
AVG DEPTH: 1.7272727272727273
NUMBER OF LINES IN FRAGMENT: 11
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 7607778bb5387a98f2e0bf5cb0c70e69c967d137
URL: https://github.com/apache/storm/commit/7607778bb5387a98f2e0bf5cb0c70e69c967d137
DESCRIPTION: Extract Method	public pushCredentials(name String, topoConf Map<String,Object>, credentials Map<String,String>, expectedUser String) : void extracted from public pushCredentials(name String, topoConf Map<String,Object>, credentials Map<String,String>) : void in class org.apache.storm.StormSubmitter
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/7607778bb5387a98f2e0bf5cb0c70e69c967d137/storm-client/src/jvm/org/apache/storm/StormSubmitter.java
REFACTORING URL: https://github.com/apache/storm/blob/7607778bb5387a98f2e0bf5cb0c70e69c967d137/storm-client/src/jvm/org/apache/storm/StormSubmitter.java#L118
DIRECTLY EXTRACTED OPERATION:
     * Push a new set of credentials to the running topology.
     *
     * @param name        the name of the topology to push credentials to.
     * @param topoConf    the topology-specific configuration, if desired. See {@link Config}.
     * @param credentials the credentials to push.
     * @param expectedUser the user you expect the topology to be owned by.
     * @throws AuthorizationException   if you are not authorized ot push credentials.
     * @throws NotAliveException        if the topology is not alive
     * @throws InvalidTopologyException if any other error happens
     */
    public static void pushCredentials(String name, Map<String, Object> topoConf, Map<String, String> credentials, String expectedUser)
        throws AuthorizationException, NotAliveException, InvalidTopologyException {
        topoConf = new HashMap(topoConf);
        topoConf.putAll(Utils.readCommandLineOpts());
        Map<String, Object> conf = Utils.readStormConfig();
        conf.putAll(topoConf);
        Map<String, String> fullCreds = populateCredentials(conf, credentials);
        if (fullCreds.isEmpty()) {
            LOG.warn("No credentials were found to push to " + name);
            return;
        }
        try {
            try (NimbusClient client = NimbusClient.getConfiguredClient(conf)) {
                LOG.info("Uploading new credentials to {}", name);
                Credentials creds = new Credentials(fullCreds);
                if (expectedUser != null) {
                    creds.set_topoOwner(expectedUser);
                }
                client.getClient().uploadNewCredentials(name, creds);
            }
            LOG.info("Finished pushing creds to topology: {}", name);
        } catch (TException e) {
            throw new RuntimeException(e);
        }
    }

PARAMS COUNT: 4
IS VOID METHOD: true
FRAGMENT LENGTH: 1810
FRAGMENT LINE AVG SIZE: 50.27777777777778
DEPTHS:
0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 3 3 2 2 3 4 4 4 5 4 4 3 3 3 3 2 1 1 
AREA: 77
AVG DEPTH: 2.138888888888889
NUMBER OF LINES IN FRAGMENT: 36
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: dd90dcadd63c579838e32090c491c9192a9105c5
URL: https://github.com/apache/storm/commit/dd90dcadd63c579838e32090c491c9192a9105c5
DESCRIPTION: Extract Method	private addLagResultForKafkaSpout(finalResult Map<String,Map<String,Object>>, spoutId String, spoutSpec SpoutSpec) : void extracted from public lag(stormTopology StormTopology, topologyConf Map<String,Object>) : Map<String,Map<String,Object>> in class org.apache.storm.utils.TopologySpoutLag
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/dd90dcadd63c579838e32090c491c9192a9105c5/storm-core/src/jvm/org/apache/storm/utils/TopologySpoutLag.java
REFACTORING URL: https://github.com/apache/storm/blob/dd90dcadd63c579838e32090c491c9192a9105c5/storm-core/src/jvm/org/apache/storm/utils/TopologySpoutLag.java#L79
DIRECTLY EXTRACTED OPERATION:
        throws IOException {
        ComponentCommon componentCommon = spoutSpec.get_common();
        String json = componentCommon.get_json_conf();
        if (json != null && !json.isEmpty()) {
            Map<String, Object> jsonMap = null;
            try {
                jsonMap = (Map<String, Object>) JSONValue.parseWithException(json);
            } catch (ParseException e) {
                throw new IOException(e);
            }

            if (jsonMap.containsKey(TOPICS_CONFIG)
                && jsonMap.containsKey(GROUPID_CONFIG)
                && jsonMap.containsKey(BOOTSTRAP_CONFIG)) {
                finalResult.put(spoutId, getLagResultForNewKafkaSpout(spoutId, spoutSpec));
            }
        }
    }

PARAMS COUNT: 3
IS VOID METHOD: true
FRAGMENT LENGTH: 734
FRAGMENT LINE AVG SIZE: 38.63157894736842
DEPTHS:
1 2 2 2 3 3 4 4 4 3 3 3 3 3 4 3 2 1 1 
AREA: 51
AVG DEPTH: 2.6842105263157894
NUMBER OF LINES IN FRAGMENT: 19
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: d86ef7d2d5f21d5e4f29fce97a681f33c4ffa0ad
URL: https://github.com/apache/storm/commit/d86ef7d2d5f21d5e4f29fce97a681f33c4ffa0ad
DESCRIPTION: Extract Method	private createProducerCallback(input Tuple) : Callback extracted from protected process(input Tuple) : void in class org.apache.storm.kafka.bolt.KafkaBolt
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/d86ef7d2d5f21d5e4f29fce97a681f33c4ffa0ad/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/bolt/KafkaBolt.java
REFACTORING URL: https://github.com/apache/storm/blob/d86ef7d2d5f21d5e4f29fce97a681f33c4ffa0ad/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/bolt/KafkaBolt.java#L148
DIRECTLY EXTRACTED OPERATION:
     * Creates the Callback to send to the Producer. Using this Callback will also execute
     * the user defined Callback, if provided.
     */
    private Callback createProducerCallback(final Tuple input) {
        return (ignored, e) -> {
            synchronized (collector) {
                if (e != null) {
                    collector.reportError(e);
                    collector.fail(input);
                } else {
                    collector.ack(input);
                }

                // User defined Callback
                if (providedCallback != null) {
                    providedCallback.onCompletion(ignored, e);
                }
            }
        };
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 693
FRAGMENT LINE AVG SIZE: 33.0
DEPTHS:
0 1 1 1 2 3 4 5 5 5 5 4 4 4 4 5 4 3 2 1 1 
AREA: 64
AVG DEPTH: 3.0476190476190474
NUMBER OF LINES IN FRAGMENT: 21
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private createTestTuple(values String...) : Tuple extracted from public testSimple() : void in class org.apache.storm.kafka.bolt.KafkaBoltTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/d86ef7d2d5f21d5e4f29fce97a681f33c4ffa0ad/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/bolt/KafkaBoltTest.java
REFACTORING URL: https://github.com/apache/storm/blob/d86ef7d2d5f21d5e4f29fce97a681f33c4ffa0ad/external/storm-kafka-client/src/test/java/org/apache/storm/kafka/bolt/KafkaBoltTest.java#L61
DIRECTLY EXTRACTED OPERATION:
        MkTupleParam param = new MkTupleParam();
        param.setFields("key", "message");
        return Testing.testTuple(Arrays.asList(values), param);
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 163
FRAGMENT LINE AVG SIZE: 32.6
DEPTHS:
1 2 2 1 1 
AREA: 7
AVG DEPTH: 1.4
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: c69a23cfe661afd7862201d94b45282e4450b9ee
URL: https://github.com/apache/storm/commit/c69a23cfe661afd7862201d94b45282e4450b9ee
DESCRIPTION: Extract Method	private interpretConstraint(constraint ColumnConstraint, fieldIdx int) : void extracted from public field(name String, type SqlDataTypeSpec, constraint ColumnConstraint) : TableBuilderInfo in class org.apache.storm.sql.compiler.CompilerUtil.TableBuilderInfo
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/c69a23cfe661afd7862201d94b45282e4450b9ee/sql/storm-sql-core/src/jvm/org/apache/storm/sql/compiler/CompilerUtil.java
REFACTORING URL: https://github.com/apache/storm/blob/c69a23cfe661afd7862201d94b45282e4450b9ee/sql/storm-sql-core/src/jvm/org/apache/storm/sql/compiler/CompilerUtil.java#L89
DIRECTLY EXTRACTED OPERATION:
            if (constraint instanceof ColumnConstraint.PrimaryKey) {
                ColumnConstraint.PrimaryKey pk = (ColumnConstraint.PrimaryKey) constraint;
                Preconditions.checkState(primaryKey == -1, "There are more than one primary key in the table");
                primaryKey = fieldIdx;
                primaryKeyMonotonicity = pk.monotonicity();
            }
        }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 396
FRAGMENT LINE AVG SIZE: 49.5
DEPTHS:
3 4 4 4 4 3 2 2 
AREA: 26
AVG DEPTH: 3.25
NUMBER OF LINES IN FRAGMENT: 8
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: ba5260774bbd436e81da14a97c072e399a70a896
URL: https://github.com/apache/storm/commit/ba5260774bbd436e81da14a97c072e399a70a896
DESCRIPTION: Extract Method	private throwIfEmittingForUnassignedPartition(currBatchTp TopicPartition) : void extracted from public emitPartitionBatch(tx TransactionAttempt, collector TridentCollector, currBatchPartition KafkaTridentSpoutTopicPartition, lastBatch Map<String,Object>) : Map<String,Object> in class org.apache.storm.kafka.spout.trident.KafkaTridentSpoutEmitter
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/ba5260774bbd436e81da14a97c072e399a70a896/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitter.java
REFACTORING URL: https://github.com/apache/storm/blob/ba5260774bbd436e81da14a97c072e399a70a896/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/trident/KafkaTridentSpoutEmitter.java#L198
DIRECTLY EXTRACTED OPERATION:
        final Set<TopicPartition> assignments = consumer.assignment();
        if (!assignments.contains(currBatchTp)) {
            throw new IllegalStateException("The spout is asked to emit tuples on a partition it is not assigned."
                + " This indicates a bug in the TopicFilter or ManualPartitioner implementations."
                + " The current partition is [" + currBatchTp + "], the assigned partitions are [" + assignments + "].");
        }
    }

PARAMS COUNT: 1
IS VOID METHOD: true
FRAGMENT LENGTH: 474
FRAGMENT LINE AVG SIZE: 59.25
DEPTHS:
1 2 3 3 3 2 1 1 
AREA: 16
AVG DEPTH: 2.0
NUMBER OF LINES IN FRAGMENT: 8
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: bdcf1683732e9c5cf7fae3f5297295b12b37e26d
URL: https://github.com/apache/storm/commit/bdcf1683732e9c5cf7fae3f5297295b12b37e26d
DESCRIPTION: Extract Method	private downloadLogUrl(downloadUrl URL, urlContent String) : void extracted from public getLogs(componentId String) : String in class org.apache.storm.st.wrapper.TopoWrap
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/bdcf1683732e9c5cf7fae3f5297295b12b37e26d/integration-test/src/test/java/org/apache/storm/st/wrapper/TopoWrap.java
REFACTORING URL: https://github.com/apache/storm/blob/bdcf1683732e9c5cf7fae3f5297295b12b37e26d/integration-test/src/test/java/org/apache/storm/st/wrapper/TopoWrap.java#L339
DIRECTLY EXTRACTED OPERATION:
        final String userDir = System.getProperty("user.dir");
        final File target = new File(userDir, "target");
        final File logDir = new File(target, "logs");
        final File logFile = new File(logDir, downloadUrl.getHost() + "-" + downloadUrl.getFile().split("/")[2]);
        try {
            FileUtils.forceMkdir(logDir);
            FileUtils.write(logFile, urlContent, StandardCharsets.UTF_8);
        } catch (Throwable throwable) {
            LOG.info("Caught exception: " + ExceptionUtils.getFullStackTrace(throwable));
        }
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 565
FRAGMENT LINE AVG SIZE: 47.083333333333336
DEPTHS:
1 2 2 2 2 3 3 3 3 2 1 1 
AREA: 25
AVG DEPTH: 2.0833333333333335
NUMBER OF LINES IN FRAGMENT: 12
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: 528ab30b5c49dbeae37df4cb9a97c12ee8989c01
URL: https://github.com/apache/storm/commit/528ab30b5c49dbeae37df4cb9a97c12ee8989c01
DESCRIPTION: Extract Method	private commitIfNecessary() : void extracted from private shutdown() : void in class org.apache.storm.kafka.spout.KafkaSpout
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/528ab30b5c49dbeae37df4cb9a97c12ee8989c01/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java
REFACTORING URL: https://github.com/apache/storm/blob/528ab30b5c49dbeae37df4cb9a97c12ee8989c01/external/storm-kafka-client/src/main/java/org/apache/storm/kafka/spout/KafkaSpout.java#L650
DIRECTLY EXTRACTED OPERATION:
        if (isAtLeastOnceProcessing()) {
            commitOffsetsForAckedTuples();
        }
    }

IS VOID METHOD: true
FRAGMENT LENGTH: 101
FRAGMENT LINE AVG SIZE: 20.2
DEPTHS:
2 3 2 1 1 
AREA: 9
AVG DEPTH: 1.8
NUMBER OF LINES IN FRAGMENT: 5
---REFACTORING_FINISH---
-----REFACTORINGS_END-----
COMMIT ID: e2308285d28a2df4a1435a1f4fb304630749c29a
URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a
DESCRIPTION: Extract Method	private getChannelSaslClient(channel Channel) : KerberosSaslNettyClient extracted from public messageReceived(ctx ChannelHandlerContext, event MessageEvent) : void in class org.apache.storm.messaging.netty.KerberosSaslClientHandler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/KerberosSaslClientHandler.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/KerberosSaslClientHandler.java#L86
DIRECTLY EXTRACTED OPERATION:
        // Generate SASL response to server using Channel-local SASL client.
        KerberosSaslNettyClient saslNettyClient = channel.attr(KerberosSaslNettyClientState.KERBEROS_SASL_NETTY_CLIENT).get();
        if (saslNettyClient == null) {
            throw new Exception("saslNettyClient was unexpectedly null for channel:" + channel);
        }
        return saslNettyClient;
    }

PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 389
FRAGMENT LINE AVG SIZE: 48.625
DEPTHS:
1 2 2 3 2 2 1 1 
AREA: 14
AVG DEPTH: 1.75
NUMBER OF LINES IN FRAGMENT: 8
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private handleControlMessage(ctx ChannelHandlerContext, controlMessage ControlMessage) : void extracted from public messageReceived(ctx ChannelHandlerContext, event MessageEvent) : void in class org.apache.storm.messaging.netty.KerberosSaslClientHandler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/KerberosSaslClientHandler.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/KerberosSaslClientHandler.java#L95
DIRECTLY EXTRACTED OPERATION:
        Channel channel = ctx.channel();
        KerberosSaslNettyClient saslNettyClient = getChannelSaslClient(channel);
        if (controlMessage == ControlMessage.SASL_COMPLETE_REQUEST) {
                LOG.debug("Server has sent us the SaslComplete message. Allowing normal work to proceed.");

                if (!saslNettyClient.isComplete()) {
                String errorMessage =
                    "Server returned a Sasl-complete message, but as far as we can tell, we are not authenticated yet.";
                LOG.error(errorMessage);
                throw new Exception(errorMessage);
                }
            ctx.pipeline().remove(this);
            this.client.channelReady(channel);

            // We call fireChannelRead since the client is allowed to
                // perform this request. The client's request will now proceed
                // to the next pipeline component namely StormClientHandler.
            ctx.fireChannelRead(controlMessage);
            } else {
            LOG.warn("Unexpected control message: {}", controlMessage);
            }
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 1101
FRAGMENT LINE AVG SIZE: 47.869565217391305
DEPTHS:
1 2 2 3 3 3 4 4 4 4 3 3 3 3 3 3 3 3 3 3 2 1 1 
AREA: 64
AVG DEPTH: 2.782608695652174
NUMBER OF LINES IN FRAGMENT: 23
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private handleSaslMessageToken(ctx ChannelHandlerContext, saslMessageToken SaslMessageToken) : void extracted from public messageReceived(ctx ChannelHandlerContext, event MessageEvent) : void in class org.apache.storm.messaging.netty.KerberosSaslClientHandler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/KerberosSaslClientHandler.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/KerberosSaslClientHandler.java#L119
DIRECTLY EXTRACTED OPERATION:
        Channel channel = ctx.channel();
        KerberosSaslNettyClient saslNettyClient = getChannelSaslClient(channel);
            LOG.debug("Responding to server's token of length: {}",
            saslMessageToken.getSaslToken().length);

            // Generate SASL response (but we only actually send the response if
            // it's non-null.
            byte[] responseToServer = saslNettyClient
            .saslResponse(saslMessageToken);
            if (responseToServer == null) {
                // If we generate a null response, then authentication has completed
                // (if not, warn), and return without sending a response back to the
                // server.
                LOG.debug("Response to server is null: authentication should now be complete.");
                if (!saslNettyClient.isComplete()) {
                    LOG.warn("Generated a null response, but authentication is not complete.");
                    throw new Exception("Our reponse to the server is null, but as far as we can tell, we are not authenticated yet.");
                }
            this.client.channelReady(channel);
            } else {
                LOG.debug("Response to server token has length: {}",
                          responseToServer.length);
            // Construct a message containing the SASL response and send it to the
            // server.
            SaslMessageToken saslResponse = new SaslMessageToken(responseToServer);
            channel.writeAndFlush(saslResponse, channel.voidPromise());
        }
    }
}
PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 1564
FRAGMENT LINE AVG SIZE: 53.93103448275862
DEPTHS:
1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 4 4 3 3 3 3 3 3 3 3 3 2 1 0 
AREA: 72
AVG DEPTH: 2.4827586206896552
NUMBER OF LINES IN FRAGMENT: 29
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private getChannelSaslNettyClient(channel Channel) : SaslNettyClient extracted from public messageReceived(ctx ChannelHandlerContext, event MessageEvent) : void in class org.apache.storm.messaging.netty.SaslStormClientHandler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/SaslStormClientHandler.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/SaslStormClientHandler.java#L79
DIRECTLY EXTRACTED OPERATION:
        // Generate SASL response to server using Channel-local SASL client.
        SaslNettyClient saslNettyClient = channel.attr(SaslNettyClientState.SASL_NETTY_CLIENT).get();
        if (saslNettyClient == null) {
            throw new Exception("saslNettyClient was unexpectedly "
                + "null for channel: " + channel);
        }
        return saslNettyClient;
    }
    
PARAMS COUNT: 1
IS VOID METHOD: false
FRAGMENT LENGTH: 390
FRAGMENT LINE AVG SIZE: 43.333333333333336
DEPTHS:
1 2 2 3 3 2 2 1 1 
AREA: 17
AVG DEPTH: 1.8888888888888888
NUMBER OF LINES IN FRAGMENT: 9
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private handleControlMessage(ctx ChannelHandlerContext, controlMessage ControlMessage) : void extracted from public messageReceived(ctx ChannelHandlerContext, event MessageEvent) : void in class org.apache.storm.messaging.netty.SaslStormClientHandler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/SaslStormClientHandler.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/SaslStormClientHandler.java#L89
DIRECTLY EXTRACTED OPERATION:
        SaslNettyClient saslNettyClient = getChannelSaslNettyClient(ctx.channel());
        if (controlMessage == ControlMessage.SASL_COMPLETE_REQUEST) {
            LOG.debug("Server has sent us the SaslComplete "
                + "message. Allowing normal work to proceed.");

            if (!saslNettyClient.isComplete()) {
                LOG.error("Server returned a Sasl-complete message, "
                    + "but as far as we can tell, we are not authenticated yet.");
                throw new Exception("Server returned a "
                    + "Sasl-complete message, but as far as "
                    + "we can tell, we are not authenticated yet.");
            }
            ctx.pipeline().remove(this);
            this.client.channelReady(ctx.channel());

            // We call fireMessageRead since the client is allowed to
            // perform this request. The client's request will now proceed
            // to the next pipeline component namely StormClientHandler.
            ctx.fireChannelRead(controlMessage);
        } else {
            LOG.warn("Unexpected control message: {}", controlMessage);
        }
    }
    
PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 1156
FRAGMENT LINE AVG SIZE: 48.166666666666664
DEPTHS:
1 2 3 3 3 3 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 2 1 1 
AREA: 69
AVG DEPTH: 2.875
NUMBER OF LINES IN FRAGMENT: 24
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private handleSaslMessageToken(ctx ChannelHandlerContext, saslMessageToken SaslMessageToken) : void extracted from public messageReceived(ctx ChannelHandlerContext, event MessageEvent) : void in class org.apache.storm.messaging.netty.SaslStormClientHandler
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/SaslStormClientHandler.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-client/src/jvm/org/apache/storm/messaging/netty/SaslStormClientHandler.java#L114
DIRECTLY EXTRACTED OPERATION:
        Channel channel = ctx.channel();
        SaslNettyClient saslNettyClient = getChannelSaslNettyClient(channel);
        LOG.debug("Responding to server's token of length: "
                  + saslMessageToken.getSaslToken().length);

        // Generate SASL response (but we only actually send the response if
        // it's non-null.
        byte[] responseToServer = saslNettyClient
            .saslResponse(saslMessageToken);
        if (responseToServer == null) {
            // If we generate a null response, then authentication has completed
            // (if not, warn), and return without sending a response back to the
            // server.
            LOG.debug("Response to server is null: "
                      + "authentication should now be complete.");
            if (!saslNettyClient.isComplete()) {
                LOG.warn("Generated a null response, "
                         + "but authentication is not complete.");
                throw new Exception("Server response is null, but as far as "
                                    + "we can tell, we are not authenticated yet.");
            }
            this.client.channelReady(channel);
            return;
        } else {
            LOG.debug("Response to server token has length:"
                      + responseToServer.length);
        }
        // Construct a message containing the SASL response and send it to the
        // server.
        SaslMessageToken saslResponse = new SaslMessageToken(responseToServer);
        channel.writeAndFlush(saslResponse, channel.voidPromise());
    }

PARAMS COUNT: 2
IS VOID METHOD: true
FRAGMENT LENGTH: 1591
FRAGMENT LINE AVG SIZE: 48.21212121212121
DEPTHS:
1 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 4 4 4 4 3 3 3 3 3 3 2 2 2 2 2 1 1 
AREA: 83
AVG DEPTH: 2.515151515151515
NUMBER OF LINES IN FRAGMENT: 33
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private send(client IConnection, taskId int, messageBytes byte[]) : void extracted from private doTestBasic(stormConf Map<String,Object>) : void in class org.apache.storm.messaging.netty.NettyTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-core/test/jvm/org/apache/storm/messaging/netty/NettyTest.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-core/test/jvm/org/apache/storm/messaging/netty/NettyTest.java#L105
DIRECTLY EXTRACTED OPERATION:
        client.send(Collections.singleton(new TaskMessage(taskId, messageBytes)).iterator());
    }

PARAMS COUNT: 3
IS VOID METHOD: true
FRAGMENT LENGTH: 101
FRAGMENT LINE AVG SIZE: 33.666666666666664
DEPTHS:
1 1 1 
AREA: 3
AVG DEPTH: 1.0
NUMBER OF LINES IN FRAGMENT: 3
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private send(client IConnection, taskId int, messageBytes byte[]) : void extracted from private doTestLoad(stormConf Map<String,Object>) : void in class org.apache.storm.messaging.netty.NettyTest
REFACTORING FILE DIFF URL: https://github.com/apache/storm/commit/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-core/test/jvm/org/apache/storm/messaging/netty/NettyTest.java
REFACTORING URL: https://github.com/apache/storm/blob/e2308285d28a2df4a1435a1f4fb304630749c29a/storm-core/test/jvm/org/apache/storm/messaging/netty/NettyTest.java#L105
DIRECTLY EXTRACTED OPERATION:
        client.send(Collections.singleton(new TaskMessage(taskId, messageBytes)).iterator());
    }

PARAMS COUNT: 3
IS VOID METHOD: true
FRAGMENT LENGTH: 101
FRAGMENT LINE AVG SIZE: 33.666666666666664
DEPTHS:
1 1 1 
AREA: 3
AVG DEPTH: 1.0
NUMBER OF LINES IN FRAGMENT: 3
---REFACTORING_FINISH---
DESCRIPTION: Extract Method	private send(client IConnection, taskId int, messageBytes byte[]) : voi